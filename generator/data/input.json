[
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "security"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Are there any regulatory or governance requirements?",
    "context": "Regulatory requirements may mandate that operational data, such as application logs and metrics, remain within a certain geo-political region. This has obvious implications for how the application should be operationalized.",
    "recommendation": "Make sure that all regulatory requirements are known and well understood. Create processes for obtaining attestations and be familiar with the [Microsoft Trust Center](https://www.microsoft.com/trust-center). Regulatory requirements like data sovereignty and others might affect the overall architecture as well as the selection and configuration of specific PaaS and SaaS services.",
    "id": "app_design_datasovereignty"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Does the application have components on-premises or in another cloud platform?",
    "context": "Hybrid and cross-cloud workloads with components on-premises or on different cloud platforms, such as AWS or GCP, introduce additional operational considerations around achieving a 'single pane of glass' for operations",
    "recommendation": "Make sure that any hybrid or cross cloud relationships and dependencies are well understood.",
    "id": "app_design_hybrid"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Is the application implemented with strategies for resiliency and self-healing?",
    "context": "Strategies for resiliency and self-healing include retrying transient failures and failing over to a secondary instance or even another region (see [Designing resilient Azure applications](https://docs.microsoft.com/en-us/azure/architecture/framework/resiliency/app-design))",
    "recommendation": "Consider implementing strategies and capabilities for resiliency and self-healing needed to achieve workload availability targets.",
    "id": "app_design_selfhealing"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Was the application built natively for the cloud or was an existing on-premises system migrated?",
    "context": "Understanding if the application is cloud-native or not provides a very useful high level indication about potential technical debt for operability",
    "recommendation": "While cloud-native workloads are preferred, migrated or modernized applications are reality and they might not be aware of the available functionality like auto-scaling, platform notifications and other the underlaying cloud platform can offer. Make sure to understand the limitations and implement workarounds if available.",
    "id": "app_design_cloudnative"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Are Azure Tags used to enrich Azure resources with operational meta-data?",
    "context": "Using tags can help to manage resources and make it easier to find relevant items during operational procedures.",
    "recommendation": "Azure Tags provide the ability to associate critical meta-data as a name-value pair, such as billing information (e.g. cost center code), environment information (e.g. environment type), with Azure resources, resource groups, and subscriptions. See [Tagging Strategies](https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/decision-guides/resource-tagging) for best practices.",
    "id": "app_design_tagging"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Does the application have a well-defined naming standard for Azure resources?",
    "context": "A well-defined naming convention is important for overall operations to be able to easily determine the usage of certain resources.",
    "recommendation": "Having a well-defined naming convention is important for overall operations, particularly for large application platforms where there are numerous resources([Naming Conventions](https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/naming-and-tagging))",
    "id": "app_design_namingstandards"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Targets & Non Functional Requirements",
    "title": "Are availability targets such as Service Level Agreements (SLAs), Service Level Indicators (SLIs), and Service Level Objectives (SLOs) defined for the application and/or key scenarios?",
    "context": "Understanding customer availability expectations is vital to reviewing overall operations for the application. For instance, if a customer is striving to achieve an application SLO of 99.999%, the level of inherent operational actionality required by the application is going to far greater than if an SLO of 99.9% was the aspiration",
    "recommendation": "Having clearly defined availability targets is crucial in order to have a goal to work and measure against. This will also determine which services an application can leverage vs. those which do not qualify in terms of the SLA they offer.",
    "children": [
      {
        "title": "Are SLAs/SLOs/SLIs for all leveraged dependencies understood?",
        "context": "Availability targets for any dependencies leveraged by the application should be understood and ideally align with application targets",
        "recommendation": "Make sure SLAs/SLOs/SLIs for all leveraged dependencies are understood",
        "id": "app_design_targets_deps"
      },
      {
        "title": "Has a composite SLA been calculated for the application and/or key scenarios using Azure SLAs?",
        "context": "A composite SLA captures the end-to-end SLA across all application components and dependencies. It is calculated using the individual SLAs of Azure services housing application components and provides an important indicator of designed availability in relation to customer expectations and targets([Composite SLAs](https://docs.microsoft.com/en-us/azure/architecture/framework/resiliency/business-metrics#understand-service-level-agreements))",
        "recommendation": "Make sure the composite SLA of all components and dependencies on the critical paths are understood.",
        "id": "app_design_compositesla"
      },
      {
        "title": "Are availability targets considered while the system is running in disaster recovery mode?",
        "context": "The above defined targets might or might not be applied when running in DR mode. This depends from application to application.",
        "recommendation": "If targets must also apply in a failure state then an n+1 model should be used to achieve greater availability and resiliency, where n is the capacity needed to deliver required availability",
        "id": "app_design_targets_drmode"
      },
      {
        "title": "Are these availability targets monitored and measured?",
        "context": "Monitoring and measuring application availability is vital to qualifying overall application health and progress towards defined targets.",
        "recommendation": "Make sure you measure and monitor key targets such as\n- **Mean Time Between Failures (MTBF)**: The average time between failures of a particular component\n- **Mean Time Between Failures (MTBF)**: The average time between failures of a particular component",
        "id": "app_design_targets_smonitoring"
      },
      {
        "title": "What are the consequences if availability targets are not satisfied?",
        "context": "Are there any penalties, such as financial charges, associated with failing to meet SLA commitments",
        "recommendation": "It should be fully understood what are the consequences if availability targets are not satisfied. This will also inform when to initiate a failover case.",
        "id": "app_design_targets_notsatisfied"
      }
    ],
    "id": "app_design_availabilitytargets"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Targets & Non Functional Requirements",
    "title": "Are recovery targets such as Recovery Time Objective (RTO) and Recovery Point Objective (RPO) defined for the application and/or key scenarios?",
    "context": "Understanding customer reliability expectations is vital to reviewing the overall reliability of the application. For instance, if a customer is striving to achieve an application RTO of less than a minute then back-up based and active-passive disaster recovery strategies are unlikely to be appropriate \nRecovery time objective (RTO): The maximum acceptable time the application is unavailable after a disaster incident \nRecovery point objective (RPO): The maximum duration of data loss that is acceptable during a disaster event",
    "recommendation": "Recovery targets should be defined in accordance to the required RTO and RPO targets for the workloads.",
    "id": "app_design_recovery_targets"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Targets & Non Functional Requirements",
    "title": "Are there well defined performance requirements for the application and/or key scenarios?",
    "context": "Non-functional performance requirements, such as those relating to end-user experiences (e.g. average and maximum response times) are vital to assessing the overall health of an application, and is a critical lens required for assessing operations",
    "recommendation": "Work with stakeholders to identify sensible non-functional requirements based on business requirements, research and user testing.",
    "children": [
      {
        "title": "Does the application have predictable traffic patterns? Or is load highly volatile?",
        "context": "Understanding the expected application load and known spikes, such as Black Friday for retail applications, is important when assessing operational effectiveness",
        "recommendation": "Traffic patterns should be identified by analyzing historical traffic data and the effect of significant external events on the application.",
        "id": "app_design_performance_traffic_patterns"
      },
      {
        "title": "Are there any targets defined for the time it takes to perform scale operations?",
        "context": "Scale operations (horizontal - changing the number of identical instances, vertical - switching to more/less powerful instances) can be fast, but usually take time to complete. It's important to understand how this delay affects the application under load and if degraded performance is acceptable.",
        "recommendation": "The application should be designed to scale to cope with spikes in load in-line with what is an acceptable duration for degraded performance.",
        "id": "app_design_performance_scale_targets"
      },
      {
        "title": "What is the maximum traffic volume the application is expected to serve without performance degradation?",
        "context": "Scale requirements the application must be able to effectively satisfy, such as the number of concurrent users or requests per second, is a critical lens for assessing operations.",
        "recommendation": "Traffic limits for the application should be defined in quantified and measurable manner.",
        "id": "app_design_performance_maximum_traffic"
      },
      {
        "title": "Are these performance targets monitored and measured across the application and/or key scenarios?",
        "context": "Monitoring and measuring end-to-end application performance is vital to qualifying overall application health and progress towards defined targets.",
        "recommendation": "Automation and specialized tooling (such as Application Insights) should be used to orchestrate and measure application performance.",
        "id": "app_design_performance_target_monitoring"
      }
    ],
    "id": "app_design_performance_requirements"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Key Scenarios",
    "title": "Have critical system flows through the application been defined for all key business scenarios?",
    "context": "Understanding critical system flows is vital to assessing overall operational effectiveness, and should be used to inform a health model for the application.",
    "recommendation": "Path-wise analysis should be used to define critical system flows for key business scenarios, such as the checkout process for an eCommerce application.",
    "children": [
      {
        "title": "Do these critical system flows have distinct availability, performance, or recovery targets?",
        "context": "Critical sub-systems or paths through the application may have higher expectations around availability, recovery, and performance due to the criticality of associated business scenarios and functionality.",
        "recommendation": "Targets should be specific and measurable.",
        "id": "app_design_critical_flows_targets"
      }
    ],
    "id": "app_design_critical_flows"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Key Scenarios",
    "title": "Are there any application components which are less critical and have lower availability or performance requirements?",
    "context": "Some less critical components or paths through the application may have lower expectations around availability, recovery, and performance.",
    "recommendation": "Identify if there are components with more relaxed performance requirements.",
    "id": "app_design_less_critical_components"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Dependencies",
    "title": "Are all internal and external dependencies identified and categorized as either weak or strong?",
    "context": "Internal dependencies describe components within the application scope which are required for the application to fully operate, while external dependencies captures required components outside the scope of the application, such as another application or third-party service.",
    "recommendation": "Dependencies may be categorized as either strong or weak based on whether or not the application is able to continue operating in a degraded fashion in their absence. ([Twelve-Factor App: Dependencies](https://12factor.net/dependencies))",
    "children": [
      {
        "title": "Do you maintain a complete list of application dependencies?",
        "context": "Examples of typical dependencies include platform dependencies outside the remit of the application, such as Azure Active Directory, Express Route, or a central NVA (Network Virtual Appliance), as well as application dependencies such as APIs which may be in-house or externally owned by a third-party.",
        "recommendation": "Map application dependencies either as a simple list or a document (usually this is part of a design document or reference architecture).",
        "id": "app_design_dependencies_list"
      },
      {
        "title": "Is the impact of an outage with each dependency well understood?",
        "context": "Strong dependencies play a critical role in application function and availability meaning their absence will have a significant impact, while the absence of weak dependencies may only impact specific features and not affect overall availability.",
        "recommendation": "Classify dependencies either as strong or weak. This will help identify which components are essential to the application.",
        "id": "app_design_dependencies_outage_impact"
      }
    ],
    "id": "app_design_dependencies_categorized"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Dependencies",
    "title": "Are SLAs and support agreements in place for all critical dependencies?",
    "context": "Service Level Agreement (SLA) represents a commitment around performance and availability of the application. Understanding the SLA of individual components within the system is essential in order to define reliability targets.",
    "recommendation": "The operational commitments of all external and internal dependencies should be understood to inform the broader application operations and health model.",
    "id": "app_design_sla"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "security"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Application Composition",
    "title": "What Azure services are used by the application?",
    "context": "It is important to understand what Azure services, such as App Services and Event Hub, are used by the application platform to host both application code and data.",
    "recommendation": "All Azure services in use should be identified.",
    "children": [
      {
        "title": "What operational features/capabilities are used for leveraged services?",
        "context": "Operational capabilities, such as auto-scale and auto-heal for AppServices, can reduce management overheads and support operational effectiveness.",
        "recommendation": "Make sure you understand the operational features/capabilities available and how they can be used in the solution.",
        "id": "app_design_services_operational_features"
      },
      {
        "title": "What technologies and frameworks are used by the application?",
        "context": "It is important to understand what technologies are used by the application and must be managed, such as .NET Core , Spring, or Node.js.",
        "recommendation": "All technologies and frameworks should be identified. Vulnerabilities of these dependencies must be understood (there are automated solutions on the market that can help: [OWASP Dependency-Check](https://owasp.org/www-project-dependency-check/) or [NPM audit](https://docs.npmjs.com/cli/audit)).",
        "id": "app_design_services_frameworks"
      }
    ],
    "id": "app_design_services_used"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Application Composition",
    "title": "Are components hosted on shared application or data platforms which are used by other applications?",
    "context": "Do application components leverage shared data platforms, such as a central data lake, or application hosting platforms, such as a centrally managed AKS or ASE cluster?",
    "recommendation": "Make sure you understand the design decisions and implications of using shared hosting platforms.",
    "id": "app_design_shared_platforms"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Application Composition",
    "title": "Do you monitor and regularly review new features and capabilities?",
    "context": "Azure is continuously evolving, with new features and services becoming available which may be beneficial for the application.",
    "recommendation": "Keep up to date on newest developments and feature updates, at least for services most relevant to your application.",
    "children": [
      {
        "title": "Do you subscribe to Azure service announcements for new features and capabilities?",
        "context": "Service announcements provide insights into new features and services, as well as features or services which become deprecated.",
        "recommendation": "Use announcement subscriptions to stay up to date.",
        "id": "app_design_new_features_announcements"
      }
    ],
    "id": "app_design_new_features"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Application Level Monitoring",
    "title": "Is an Application Performance Management (APM) tool used collect application level logs?",
    "context": "In order to successfully maintain the application it's important to 'turn the lights on' and have clear visibility of important metrics both in real-time and historically.",
    "recommendation": "An APM technology, such as Application Insights, should be used to manage the performance and availability of the application, aggregating application level logs and events for subsequent interpretation.",
    "id": "health_apm"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Application Level Monitoring",
    "title": "Are application logs collected from different application environments?",
    "context": "Application logs support the end-to-end application lifecycle. Logging is essential in understanding how the application operates in various environments and what events occur and under which conditions.",
    "recommendation": "Application logs and events should be collected across all major environments. Sufficient degree of separation and filtering should be in place to ensure non-critical environments do not convolute production log interpretation.",
    "id": "health_logs_collected"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Application Level Monitoring",
    "title": "Are log messages captured in a structured format?",
    "context": "Structured format, following well-known schema can help in parsing and analyzing logs.",
    "recommendation": "Application events should ideally be captured as a structured data type with machine-readable data points which can easily be indexed and searched, rather than an unstructured string.",
    "id": "health_logs_structured"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Application Level Monitoring",
    "title": "Are log levels used to capture different types of application events?",
    "context": "Different log levels, such as INFO, WARNING, ERROR, and DEBUG can be used across environments (such as DEBUG for development environment).",
    "recommendation": "Different log levels, such as INFO, WARNING, ERROR, and DEBUG should be pre-configured and applied within relevant environments. The approach to change log levels should be simple configuration change to support operational scenarios where it is necessary to elevate the log level within an environment.",
    "id": "health_log_levels"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Application Level Monitoring",
    "title": "Are application events correlated across all application components?",
    "context": "[Distributed tracing](https://docs.microsoft.com/azure/architecture/microservices/logging-monitoring#distributed-tracing) provides the ability to build and visualize end-to-end transaction flows for the application.",
    "recommendation": "Log events coming from different application components or different component tiers of the application should be correlated to build end-to-end transaction flows. For instance, this is often achieved by using consistent correlation IDs transferred between components within a transaction.",
    "id": "health_events_correlated"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Application Level Monitoring",
    "title": "Is it possible to evaluate critical application performance targets and non-functional requirements (NFRs)?",
    "context": "",
    "recommendation": "Application level metrics should include end-to-end transaction times of key technical functions, such as database queries, response times for external API calls, failure rates of processing steps, etc.",
    "children": [
      {
        "title": "Is the end-to-end performance of critical system flows monitored?",
        "context": "To fully assess the health of key scenarios in the context of targets and NFRs, application log events across critical system flows should be correlated.",
        "recommendation": "Correlate application log events across critical system flows, such as user login.",
        "id": "health_critical_performance_monitoring"
      }
    ],
    "id": "health_critical_performance_targets"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Resource/Infrastructure Level Monitoring",
    "title": "Which log aggregation technology is used to collect logs and metrics from Azure resources?",
    "context": "Log aggregation technologies, such as Azure Log Analytics or Splunk, should be used to collate logs and metrics across all application components for subsequent evaluation. Resources may include Azure IaaS and PaaS services as well as 3rd-party appliances such as firewalls or Anti-Malware solutions used in the application. For instance, if Azure Event Hub is used, the Diagnostic Settings should be configured to push logs and metrics to the data sink([Event Hub Diagnostic Logs](https://docs.microsoft.com/azure/event-hubs/event-hubs-diagnostic-logs))",
    "recommendation": "",
    "id": "health_log_aggregation_technology"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Resource/Infrastructure Level Monitoring",
    "title": "Are you collecting Azure Activity Logs within the log aggregation tool?",
    "context": "Azure Activity Logs provide audit information about when an Azure resource is modified, such as when a virtual machine is started or stopped. Such information is extremely useful for the interpretation and troubleshooting of operational issues, as it provides transparency around configuration changes.",
    "recommendation": "Azure Activity Logs should be collected and aggregated.",
    "id": "health_activity_logs_aggregation"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Resource/Infrastructure Level Monitoring",
    "title": "Is resource-level monitoring enforced throughout the application?",
    "context": "Resource- or infrastructure-level monitoring refers to the used platform services such as Azure VMs, Express Route or SQL Database. But also covers 3rd-party solutions like an NVA.",
    "recommendation": "All application resources should be configured to route diagnostic logs and metrics to the chosen log aggregation technology. Azure Policy should also be used as a device to ensure the consistent use of diagnostic settings across the application, to enforce the desired configuration for each Azure service.",
    "id": "health_resource_monitoring"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Resource/Infrastructure Level Monitoring",
    "title": "Are logs and metrics available for critical internal dependencies?",
    "context": "To be able to build a robust application health model it is vital that visibility into the operational state of critical internal dependencies, such as a shared NVA or Express Route connection, be achieved.",
    "recommendation": "Make sure logs and key metrics of critical components are collected and stored.",
    "id": "health_logs_internal_dependencies"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Resource/Infrastructure Level Monitoring",
    "title": "Are critical external dependencies monitored?",
    "context": "It's common for applications to depend on other services or libraries. Despite these are external, it is still possible to monitor their health and availability using probes.",
    "recommendation": "Critical external dependencies, such as an API service, should be monitored to ensure operational visibility of dependency health. For instance, a probe could be used to measure the availability and latency of an external API.",
    "id": "health_critical_dependencies_monitored"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Data Interpretation & Health Modelling",
    "title": "Are application and resource level logs aggregated in a single data sink, or is it possible to cross-query events at both levels?",
    "context": "To build a robust application health model it is vital that application and resource level data be correlated and evaluated together to optimize the detection of issues and troubleshooting of detected issues.",
    "recommendation": "Implement a unified solution to aggregate and query application and resource level logs, such as Azure Log Analytics.",
    "id": "health_logs_aggregated"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Data Interpretation & Health Modelling",
    "title": "Are application level events automatically correlated with resource level metrics to quantify the current application state?",
    "context": "The overall health state can be impacted by both application-level issues as well as resource-level failures. Telemetry correlation should be used to ensure transactions can be mapped through the end-to-end application and critical system flows, as this is vital to root cause analysis for failures. Platform-level metrics and logs such as CPU percentage, network in/out, and disk operations/sec should be collected from the application to inform a health model and detect/predict issues([Telemetry correlation](https://docs.microsoft.com/azure/azure-monitor/app/correlation)). This can also help to distinguish between transient and non-transient faults",
    "recommendation": "",
    "id": "health_events_correlated_metrics"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Data Interpretation & Health Modelling",
    "title": "Is the transaction flow data used to generate application/service maps?",
    "context": "Is there a correlation between events in different services and are those visualized?",
    "recommendation": "An [Application Map](https://docs.microsoft.com/en-us/azure/azure-monitor/app/app-map?tabs=net) can to help spot performance bottlenecks or failure hotspots across components of a distributed application.",
    "id": "health_events_applicationmap"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Data Interpretation & Health Modelling",
    "title": "Is a health model used to qualify what 'healthy' and 'unhealthy' states represent for the application?",
    "context": "",
    "recommendation": "A holistic application health model should be used to quantify what 'healthy' and 'unhealthy' states represent across all application components. It is highly recommended that a 'traffic light' model be used to indicate a green/healthy state when key non-functional requirements and targets are fully satisfied and resources are optimally utilized, e.g. 95% of requests are processed in <= 500ms with AKS node utilization at x% etc. Once established, this health model should inform critical monitoring metrics across system components and operational sub-system composition. It is important to note that the health model should clearly distinguish between expected-transient but recoverable failures and a true disaster state.",
    "children": [
      {
        "title": "Are critical system flows used to inform the health model?",
        "context": "",
        "recommendation": "The health model should be able to surface the respective health of critical system flows or key subsystems to ensure appropriate operational prioritization is applied. For example, the health model should be able to represent the current state of the user login transaction flow",
        "id": "health_healthmodel_systemflows"
      },
      {
        "title": "Can the health model distinguish between transient and non-transient faults?",
        "context": "Is the health model treating all failures the same?",
        "recommendation": "The health model should clearly distinguish between expected-transient but recoverable failures and a true disaster state",
        "id": "health_healthmodel_transientfaults"
      }
    ],
    "id": "health_healthmodel"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Data Interpretation & Health Modelling",
    "title": "Are long-term trends analysed to predict operational issues before they occur?",
    "context": "Are Operations and/or analytics teams using the stored events for machine learning or similar to make predictions for the future?",
    "recommendation": "Analytics can and should be performed across long-term operational data to help inform operational strategies and also to predict what operational issues are likely to occur and when. For instance, if the average response times have been slowly increasing over time and getting closer to the maximum target",
    "id": "health_healthmodel_longtrends"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Data Interpretation & Health Modelling",
    "title": "Have retention times for logs and metrics been defined and with housekeeping mechanisms configured?",
    "context": "",
    "recommendation": "Clear retention times should be defined to allow for suitable historic analysis but also control storage costs. Suitable housekeeping tasks should also be used to archive data to cheaper storage or aggregate data for long-term trend analysis",
    "id": "health_healthmodel_retention"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Dashboarding",
    "title": "What technology is used to visualize the application health model and encompassed logs and metrics?",
    "context": "Visualization, often also called Dashboarding, refers to how data is presented to operations teams and other interested users.",
    "recommendation": "Dashboarding tools, such as Azure Monitor or Grafana, should be used to visualize metrics and events collected at the application and resource levels, to illustrate the health model and the current operational state of the application",
    "id": "app_health_dashboarding"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Dashboarding",
    "title": "Are dashboards tailored to a specific audience?",
    "context": "Is there just one big dashboard or do you build individualized solutions for different teams (e.g. networking teams might have a different interest focus than the security team).",
    "recommendation": "Dashboards should be customized to represent the precise lens of interest of the end-user. For example, the areas of interest when evaluating the current state will differ greatly between developers, security and networking. Tailored dashboards makes interpretation easier and accelerates time to detection and action",
    "id": "app_health_dashboard_tailored"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Dashboarding",
    "title": "Is Role Based Access Control (RBAC) used to control access to dashboards and underlying data?",
    "context": "Are the dashboards openly available in your organization or do you limit access based on roles etc.?",
    "recommendation": "Access to operational data may be tightly controlled to align with segregation of duties, and careful attention should be made to ensure it doesn't hinder operational effectiveness; i.e. scenarios where developers have to raise an ITSM ticket to access logs should be avoided",
    "id": "app_health_dashboard_rbac"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Alerting",
    "title": "What technology is used for alerting?",
    "context": "Alerts from tools such as Splunk or Azure Monitor proactively notify or respond to operational states that deviate from norm",
    "recommendation": "You should not rely on people to actively look for issues. Instead an alerting solution should be in place that can push notifications to relevant teams. For example by email, SMS or into an mobile app.",
    "id": "app_health_alertingtool"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Alerting",
    "title": "Are specific owners and processes defined for each alert type?",
    "context": "Having well-defined owners and response playbooks per alert is vital to optimizing operational effectiveness",
    "recommendation": "Instead of treating all alerts the same, there should be a well-defined process which determines what teams are responsible to react to which alert type.",
    "id": "app_health_alertprocesses"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Alerting",
    "title": "Are operational events prioritized based on business impact?",
    "context": "Are all alerts being treated the same or do you analyze the potential business impact when defining an alert?",
    "recommendation": "Tagging events with a specific severity or urgency helps operational teams priorities in cases where multiple events require intervention at the same time. For example, alerts concerning critical system flows might require special attention",
    "id": "app_health_alertprio"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Alerting",
    "title": "Are push notifications enabled to inform responsible parties of alerts in real time?",
    "context": "Do teams have to actively monitor the systems and dashboard or are alerts sent to them by email etc.?",
    "recommendation": "It is important that alert owners get reliably notified of alerts, which could use many communication channels such as text messages, emails or push notifications to a mobile app",
    "id": "app_health_alertpush"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Alerting",
    "title": "Is alerting integrated with an IT Service Management (ITSM) system?",
    "context": "",
    "recommendation": "ITSM systems, such as ServiceNow, can help to document issues, notify and assign responsible parties, and track issues. For example,  operational alerts from the application could for be integrated to automatically create new tickets to track resolution",
    "id": "app_health_alertitsm"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Alerting",
    "title": "Have Azure Service Health alerts been created to respond to Service-level events?",
    "context": "Azure Service Health provides a view into the health of Azure services and regions, as well as issuing service impacting communications about outages, planned maintenance activities, and other health advisories.",
    "recommendation": "Azure Service Health Alerts should be configured to operationalize Service Health events, however, Service Health alerts should not be used to detect issues due to associated latencies; there is a 5 minute SLO for automated issues, but many issues require manual interpretation to define an RCA. Instead, they should be used to provide extremely useful information to help interpret issues that have already been detected and surfaced via the health model, to inform how best to operationally respond([Azure Service Health](https://docs.microsoft.com/en-us/azure/service-health/overview))",
    "id": "app_health_servicehealth"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Alerting",
    "title": "Have Azure Resource Health alerts been created to respond to Resource-level events?",
    "context": "Azure Resource Health provides information about the health of individual resources such as a specific virtual machine, and is highly useful when diagnosing unavailable resources.",
    "recommendation": "Azure Resource Health Alerts should be configured for specific resource groups and resource types, and should be adjusted to maximize signal to noise ratios, i.e. only distribute a notification when a resource becomes unhealthy according to the application health model or due to an Azure platform initiated event. It is therefore important to consider transient issues when setting an appropriate threshold for resource unavailability, such as configuring an alert for a virtual machine with a threshold of 1 minute for unavailability before an alert is triggered",
    "id": "app_health_resourcehealth"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Alerting",
    "title": "Are Azure notifications sent to subscriptions owners received and if necessary properly routed to relevant technical stakeholders?",
    "context": "Subscription notification emails can contain important service notifications or security alerts([Azure account contact information](https://docs.microsoft.com/en-us/azure/cost-management-billing/manage/change-azure-account-profile#service-and-marketing-emails)).",
    "recommendation": "Subscription notification emails can contain important service notifications or security alerts([Azure account contact information](https://docs.microsoft.com/en-us/azure/cost-management-billing/manage/change-azure-account-profile#service-and-marketing-emails)). Thus, it is important that those notifications are received and routed to the relevant technical stakeholders.",
    "id": "app_health_subscriptionnotifications"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Recovery & Failover",
    "title": "Are recovery steps defined for failover and failback?",
    "context": "Is there a clearly defined playbook for failover and failback procedures?",
    "recommendation": "The steps required to fail over the application to a secondary Azure region in failure situations should be codified, preferably in an automated manner, to ensure capabilities exist to effectively respond to an outage in a way that limits impact. Similar codified steps should also exist to capture the process required to failback the application to the primary region once a failover triggering issue has been addressed",
    "children": [
      {
        "title": "Has the failover and failback approach been tested/validated at least once?",
        "context": "",
        "recommendation": "The precise steps required to failover and failback the application must be tested to validate the effectiveness of the defined disaster recovery approach. Testing of the disaster recovery strategy should occur according to a reasonably regular cadence, such as annually, to ensure that operational application changes do not impact the applicability of the selected approach",
        "id": "app_ops_failovertest"
      },
      {
        "title": "How is a failover decided and initiated?",
        "context": "Is this fully automated or, if not, is the decision process clearly documented?",
        "recommendation": "Regional failovers are significant operational activity and may incur some downtime, degraded functionality, or data loss depending on the recovery strategy used. Hence, the decision process as to what constitutes a failover should be clearly understood",
        "id": "app_ops_failoverdecision"
      },
      {
        "title": "Is the health model being used to classify failover situations?",
        "context": "",
        "recommendation": "A platform service outage in a specific region will likely require a failover to another region, whereas the accidental change of an firewall rule can be mitigated by a recovery process. The health model and all underlying data should be used to interpret which operational procedures should be triggered",
        "id": "app_ops_failoverhealthmodel"
      },
      {
        "title": "Can individual components of the application failover independently?",
        "context": "For example, is it possible to failover the compute cluster to a secondary region while keeping the database running in the primary region?",
        "recommendation": "Ideally failover can happen on a component-level instead of needing to failover the entire system together, when, for instance, only one service experiences an outage.",
        "id": "app_ops_failovercomponents"
      }
    ],
    "id": "app_ops_failoverplan"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Recovery & Failover",
    "title": "Are automated recovery procedures in place for common failure event?",
    "context": "Is there at least some automation for certain failure scenarios or are all those depending on manual intervention?",
    "recommendation": "Automated responses to specific events help to reduce response times and limit errors associated with manual processes. Thus, wherever possible, it is recommended to have automation in place instead of relying on manual intervention.",
    "children": [
      {
        "title": "Are these automated recovery procedures tested and validated on a regular basis?",
        "context": "",
        "recommendation": "Automated operational responses should be tested frequently as part of the normal application lifecycle to ensure operational effectiveness",
        "id": "app_ops_failoverregulartests"
      }
    ],
    "id": "app_ops_failoverautomation"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Recovery & Failover",
    "title": "Are critical manual processes defined and documented for manual failure responses?",
    "context": "While full automation is attainable, there might be cases where manual steps cannot be avoided.",
    "recommendation": "Operational runbooks should be defined to codify the procedures and relevant information needed for operations staff to respond to failures and maintain operational health",
    "children": [
      {
        "title": "Are these manual operational runbooks tested and validated on a regular basis?",
        "context": "",
        "recommendation": "Manual operational runbooks should be tested frequently as part of the normal application lifecycle to ensure appropriateness and efficiency",
        "id": "app_ops_failovermanualstepstests"
      }
    ],
    "id": "app_ops_failovermanualsteps"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Scalability & Capacity Model",
    "title": "Is there a capacity model for the application?",
    "context": "A capacity model should describe the relationships between the utilization of various components as a ratio, to capture when and how application components should scale-out.",
    "recommendation": "A capacity model should describe the relationships between the utilization of various components as a ratio, to capture when and how application components should scale-out. For instance, scaling the number of Application Gateway v2 instances may put excess pressure on downstream components unless also scaled to a degree. When modelling capacity for critical system components it is therefore recommended that an N+1 model be applied to ensure complete tolerance to transient faults, where n describes the capacity required to satisfy performance and availability requirements([Performance Efficiency - Capacity](https://docs.microsoft.com/en-us/azure/architecture/framework/scalability/capacity))",
    "id": "app_ops_scale_capacitymodel"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Scalability & Capacity Model",
    "title": "Is auto-scaling enabled for supporting PaaS and IaaS services?",
    "context": "Are built-in capabilities for automatic scale being used vs. scaling being always a manual decision?",
    "recommendation": "Leveraging built-in Auto-scaling capabilities can help to maintain system reliability in times of increased demand while not needing to overprovision resources up-front, by letting a service automatically scale within a pre-configured range of resources. It greatly simplifies management and operational burdens. However, it must take into account the capacity model, else automated scaling of one component can impact downstream services if those are not also automatically scaled accordingly.",
    "id": "app_ops_scale_autoscale"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Scalability & Capacity Model",
    "title": "Is the process to provision and deprovision capacity codified?",
    "context": "",
    "recommendation": "Fluctuation in application traffic is typically expected. To ensure optimal operation is maintained, such variations should be met by automated scalability. The significance of automated capacity responses underpinned by a robust capacity model was highlighted by the COVID-19 crisis where many applications experienced severe traffic variations. While Auto-scaling enables a PaaS or IaaS service to scale within a pre-configured (and often times limited) range of resources, is provisioning or deprovisioning capacity a more advanced and complex process of for example adding additional scale units like additional clusters, instances or deployments. The process should be codified, automated and the effects of adding/removing capacity should be well understood.",
    "id": "app_ops_scale_codified"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Scalability & Capacity Model",
    "title": "Is the impact of changes in application health on capacity fully understood?",
    "context": "For example, if an outage in an external API is mitigated by writing messages into a retry queue, this queue will get sudden spikes in load which it will need to be able to handle",
    "recommendation": "Any change in the health state of application components can influence the capacity demands on other components. Those impacts need to be fully understood and measures such as auto-scaling need to be in place to handle those.",
    "id": "app_ops_scale_healthimpact"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Scalability & Capacity Model",
    "title": "Is the required capacity (initial and future growth) within Azure service scale limits and quotas?",
    "context": "Due to physical and logical resource constraints within the platform, Azure must apply limits and quotas to service scalability, which may be either hard or soft.",
    "recommendation": "Due to physical and logical resource constraints within the platform, Azure must apply limits and quotas to service scalability, which may be either hard or soft. The application should therefore take a scale-unit approach to navigate within service limits, and where necessary consider multiple subscriptions which are often the boundary for such limits. It is highly recommended that a structured approach to scale be designed up-front rather than resorting to a 'spill and fill' model([Azure subscription and service limits, quotas, and constraints](https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/azure-subscription-service-limits))",
    "children": [
      {
        "title": "Is the required capacity (initial and future growth) available within targeted regions?",
        "context": "While the promise of the cloud is infinite scale, the reality is that there are finite resources available and as a result situations can occur where capacity can be constrained due to overall demand.",
        "recommendation": "If the application requires a large amount of capacity or expects a significant increase in capacity then effort should be invested to ensure that desired capacity is attainable within selected region(s). For applications leveraging a recovery or active-passive based disaster recovery strategy, consideration should also be given to ensure suitable capacity exists in the secondary region(s) since a regional outage can lead to a significant increase in demand within a paired region due to other customer workloads also failing over. To help mitigate this, consideration should be given to pre-provisioning resources within the secondary region([Azure Capacity](https://aka.ms/AzureCapacity))",
        "id": "app_ops_scale_futuregrowth"
      }
    ],
    "id": "app_ops_scale_limits"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Scalability & Capacity Model",
    "title": "Is capacity utilization monitored and used to forecast future growth?",
    "context": "Predicting future growth and capacity demands can prevent outages due to insufficient provisioned capacity over time.",
    "recommendation": "Especially when demand is fluctuating, it is useful to monitor historical capacity utilization to derive predictions about future growth. Azure Monitor provides the ability to collect utilization metrics for Azure services so that they can be operationalized in the context of a defined capacity model. The Azure Portal can also be used to inspect current subscription usage and quota status([Supported metrics with Azure Monitor](https://docs.microsoft.com/en-us/azure/azure-monitor/platform/metrics-supported))",
    "id": "app_ops_scale_utilmonitoring"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability",
      "security"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "Where is application configuration information stored and how does the application access it?",
    "context": "Application configuration information can be stored together with the application itself or preferably using a dedicated configuration management system like Azure App Configuration or Azure Key Vault",
    "recommendation": "Preferably configuration information is stored using a dedicated configuration management system like Azure App Configuration or Azure Key Vault so that it can be updated independently of the application code.",
    "id": "app_ops_configtool"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "Can configuration settings be changed or modified without rebuilding or redeploying the application?",
    "context": "",
    "recommendation": "Application code and configuration should not share the same lifecycle to enable operational activities that change and update specific configurations without developer involvement or redeployment",
    "id": "app_ops_configchange"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "security"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "How are passwords and other secrets managed?",
    "context": "Are secrets stored in a specially protected way or in the same way as any other application configuration?",
    "recommendation": "Tools like Azure Key Vault or HashiCorp Vault should be used to store and manage secrets securely rather than being baked into the application artefact during deployment, as this simplifies operational tasks like key rotation as well as improving overall security. Keys and secrets stored in source code should be identified with static code scanning tools. Ensure that these scans are an integrated part of the continuous integration (CI) process.",
    "id": "app_ops_secretmanagement"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability",
      "security"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "Do you have procedures in place for key/secret rotation?",
    "context": "In the situation where a key or secret becomes compromised, it is important to be able to quickly act and generate new versions. Key rotation reduces the attack vectors and should be automated and executed without any human interactions.",
    "recommendation": "Secrets (keys, certificates etc.) should be replaced once they have reached the end of their active lifetime or once they have been compromised. Renewed certificates should also use a new key. A process needs to be in place for situations where keys get compromised (leaked) and need to be regenerated on-demand. Tools, such as Azure Key Vault should ideally be used to store and manage application secrets to help with rotation processes([Key Vault Key Rotation](https://docs.microsoft.com/azure/key-vault/secrets/tutorial-rotation-dual))",
    "id": "app_ops_secretrotation"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "Does the application use Managed Identities?",
    "context": "Managed Identities in Azure can be used to securely access Azure services while removing the need to store the secrets or certificates of Service Principals([Managed Identities Overview](https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/overview))",
    "recommendation": "Wherever possible Azure Managed Identities (either system-managed or user-managed) should be used since they remove the management burden of storing and rotating keys for service principles. Thus, they provide higher security as well as easier maintenance.",
    "id": "app_ops_mi"
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "Are keys and secrets backed-up to geo-redundant storage?",
    "context": "Keys and secrets must still be available in a failover case.",
    "recommendation": "Keys and secrets should be backed up to geo-redundant storage so that they can be accessed in the event of a regional failure and support recovery objectives. In the event of a regional outage, the Key Vault service will automatically be failed over to the secondary region in a read-only state([Azure Key Vault availability and reliability](https://docs.microsoft.com/en-us/azure/key-vault/general/disaster-recovery-guidance))",
    "children": [
      {
        "title": "Are certificate/key backups and data backups stored in different geo-redundant storage accounts?",
        "context": "",
        "recommendation": "Encryption keys and data should be backed up separately to optimise the security of underlying data",
        "id": "app_ops_secrets_redundancybackups"
      }
    ],
    "id": "app_ops_secrets_redundancy"
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "Is Soft-Delete enabled for Key Vaults and Key Vault objects?",
    "context": "The Soft-Delete feature retains resources for a given retention period after a DELETE operation has been performed, while giving the appearance that the object is deleted. It helps to mitigate scenarios where resources are unintentionally, maliciously or incorrectly deleted([Azure Key Vault Soft-Delete](https://docs.microsoft.com/en-us/azure/key-vault/general/overview-soft-delete))",
    "recommendation": "Key Vault Soft Delete helps to mitigate scenarios where resources are unintentionally, maliciously or incorrectly deleted([Azure Key Vault Soft-Delete](https://docs.microsoft.com/en-us/azure/key-vault/general/overview-soft-delete)). It is therefore highly recommended to enable this.",
    "id": "app_ops_secrets_kvsoftdelete"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "security"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "Are the expiry dates of SSL certificates monitored and are processes in place to renew them?",
    "context": "Expired SSL certificates are one of the most common yet avoidable causes of application outages; even Azure and more recently Microsoft Teams have experienced outages due to expired certificates.",
    "recommendation": "Tracking expiry dates of SSL certificates and renewing them in due time is therefore highly critical. Ideally the process should be automated, although this often depends on leveraged CA. If not automated, sufficient alerting should be applied to ensure expiry dates do not go unnoticed",
    "id": "app_ops_sslcertrenewal"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Patch & Update Process (PNU)",
    "title": "Is the Patch & Update Process (PNU) process defined and for all relevant application components?",
    "context": "The PNU process will vary based on the type of Azure service used (i.e. VM, VMSS, Containers on AKS). Applications using IaaS will typically require more investment to define a PNU process",
    "recommendation": "The PNU process should be fully defined and understood for all relevant application components",
    "children": [
      {
        "title": "Is the Patch & Update Process (PNU) process automated?",
        "context": "",
        "recommendation": "Ideally the PNU process should be fully or partially automated to optimize response times for new updates and also to reduce the risks associated with manual intervention",
        "id": "app_ops_pnu_automated"
      },
      {
        "title": "Are Patch & Update Process (PNU) operations performed 'as-code'?",
        "context": "",
        "recommendation": "Performing operations should be defined 'as-code' since it helps to minimize human error and increase consistency",
        "id": "app_ops_pnu_ascode"
      }
    ],
    "id": "app_ops_pnu"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Patch & Update Process (PNU)",
    "title": "How are patches rolled back?",
    "context": "",
    "recommendation": "It is recommended to have a defined strategy in place to rollback patches in case of an error or unexpected side effects",
    "id": "app_ops_pnu_rollback"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Patch & Update Process (PNU)",
    "title": "Are emergency patches handled differently than normal updates?",
    "context": "Emergency patches might contain critical security updates that cannot wait till the next maintenance or release window",
    "recommendation": "",
    "id": "app_ops_pnu_emergency"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Patch & Update Process (PNU)",
    "title": "What is the strategy to keep up with changing dependencies?",
    "context": "",
    "recommendation": "Changing dependencies, such as new versions of packages, updated Docker images, should be factored into operational processes; the application team should be subscribed to release notes of dependent services, tools, and libraries",
    "id": "app_ops_pnu_changesdeps"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Operational Lifecycles",
    "title": "How are operational shortcomings and failures analysed?",
    "context": "",
    "recommendation": "Reviewing operational incidents where the response and remediation to issues either failed or could have been optimized is vital to improving overall operational effectiveness. Failures provide a valuable learning opportunity and in some cases these learnings can also be shared across the entire organization",
    "id": "app_ops_lifecycle_review"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Operational Lifecycles",
    "title": "Are operational procedures reviewed and refined frequently?",
    "context": "",
    "recommendation": "Operational procedures should be updated based on outcomes from frequent testing",
    "id": "app_ops_lifecycle_refinement"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Deployments",
    "title": "What is the process to deploy application releases to production?",
    "context": "",
    "recommendation": "The entire end-to-end CI/CD deployment process should be understood",
    "children": [
      {
        "title": "How long does it take to deploy an entire production environment?",
        "context": "The time it takes to perform a complete environment deployment should align with recovery targets",
        "recommendation": "The time it takes to perform a complete environment deployment should be fully understood as it needs to align with the recovery targets",
        "id": "app_deploy_cicd_duration"
      }
    ],
    "id": "app_deploy_cicd"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Deployments",
    "title": "How often are changes deployed to production?",
    "context": "Are numerous releases deployed each day or do releases have a fixed cadence, such as every quarter?",
    "recommendation": "",
    "id": "app_deploy_frequency"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Deployments",
    "title": "Can the application be deployed automatically from scratch without any manual operations?",
    "context": "Manual deployment steps introduce significant risks where human error is concerned and also increases overall deployment times.",
    "recommendation": "Manual deployment steps introduce significant risks where human error is concerned and also increases overall deployment times. Automated end-to-end deployments, with manual approval gates where necessary, should be used to ensure a consistent and efficient deployment process([Deployment considerations for DevOps](https://docs.microsoft.com/en-us/azure/architecture/framework/devops/deployment))",
    "children": [
      {
        "title": "Is there a documented process for any portions of the deployment that require manual intervention?",
        "context": "Without detailed release process documentation, there is a much higher risk of an operator improperly configuring settings for the application",
        "recommendation": "Any manual steps that are required in the deployment pipeline must be clearly documented with roles and responsibilties well defined.",
        "id": "app_deploy_manualdocs"
      }
    ],
    "id": "app_deploy_fromscratch"
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Deployments",
    "title": "How long does it take to deploy an entire production environment?",
    "context": "The time it takes for a full deployment needs to algin with recovery targets",
    "recommendation": "The entire end-to-end deployment process should be understood and align with recovery targets",
    "id": "app_deploy_duration"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability",
      "security"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Deployments",
    "title": "Can N-1 or N+1 versions be deployed via automated pipelines where N is current deployment version in production?",
    "context": "N-1 and N+1 refer to roll-back and roll-forward.",
    "recommendation": "Automated deployment pipelines should allow for quick roll-forward and roll-back deployments to address critical bugs and code updates outside of the normal deployment lifecycle",
    "id": "app_deploy_n1"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Deployments",
    "title": "Is there a defined hotfix process which bypasses normal deployment procedures?",
    "context": "",
    "recommendation": "In some scenarios there is an operational need to rapidly deploy changes, such as critical security updates. Having a defined process for how such changes can be safely and effectively performed helps greatly to prevent 'heat of the moment' issues",
    "id": "app_deploy_hotfix"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Deployments",
    "title": "Does the application deployment process leverage blue-green deployments and/or canary releases?",
    "context": "Blue/green or canary deployments are a way to gradually release new feature or changes without impacting all users at once.",
    "recommendation": "Blue-green deployments and/or canary releases can be used to deploy updates in a controlled manner that helps to minimize disruption from unanticipated deployment issues([Stage your workloads](https://docs.microsoft.com/en-us/azure/architecture/framework/devops/deployment#stage-your-workloads)) For example, Azure uses canary regions to test and validate new services and capabilities before they are more broadly rolled out to other Azure regions. Where appropriate the application can also use canary environments to validate changes before wider production rollout. Moreover, certain large application platforms may also derive benefit from leveraging Azure canary regions as a basis for validating the potential impact of Azure platform changes on the application.",
    "id": "app_deploy_bluegreen"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Deployments",
    "title": "How does the development team manage application source code, builds, and releases?",
    "context": "It is important to understand whether there is a systematic approach to the development and release process.",
    "recommendation": "The use of source code control systems, such as Azure Repos or GitHub, and build and release systems, such as Azure Pipelines or GitHub Actions, should be understood, including the corresponding processes to access, review and approve changes",
    "children": [
      {
        "title": "If Git is used for source control, what branching strategy is used?",
        "context": "While there are various valid ways, a clearly defined strategy should be in place and understood",
        "recommendation": "To optimize for collaboration and ensure developers spend less time managing version control and more time developing code, a clear and simple branching strategy should be used, such as Trunk-Based Development which is employed internally within Microsoft Engineering([Microsoft Git Strategy](https://docs.microsoft.com/en-us/azure/devops/learn/devops-at-microsoft/use-git-microsoft))",
        "id": "app_deploy_branching"
      }
    ],
    "id": "app_deploy_devprocess"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Infrastructure Deployments & Infrastructure as Code (IaC)",
    "title": "Is application infrastructure defined as code?",
    "context": "",
    "recommendation": "It is highly recommended do describe the entire infrastructure as code, using either ARM Templates, Terraform, or other tools. This allows for proper versioning and configuration management, encouraging consistency and reproducibility across environments",
    "children": [
      {
        "title": "Are any operational changes performed outside of IaC?",
        "context": "Are any resources provisioned or operationally configured manually through the Azure Portal or via Azure CLI?",
        "recommendation": "It is recommended that even small operational changes and modifications be implemented as-code to track changes and ensure they are fully reproduceable and revertible. No infrastructure changes should be done manually outside of IaC.",
        "id": "app_deploy_iacmanual"
      },
      {
        "title": "How does the application track and address configuration drift?",
        "context": "Configuration drift occurs when changes are applied outside of IaC processes such as manual changes.",
        "recommendation": "Tools like terraform support a plan command that helps to identify change and monitor configuration drift, with Azure as the ultimate source of truth",
        "id": "app_deploy_configdrift"
      }
    ],
    "id": "app_deploy_iac"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Infrastructure Deployments & Infrastructure as Code (IaC)",
    "title": "Is the process to deploy infrastructure automated?",
    "context": "",
    "recommendation": "It is recommended to use build and release tools to define automated or partially automated CI/CD pipelines for the entire infrastructure",
    "id": "app_deploy_iacautomated"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Build Environments",
    "title": "Do critical test environments have 1:1 parity with the production environment?",
    "context": "Do test environment differ from production in more than just smaller SKUs being used, e.g. by sharing components between different envs?",
    "recommendation": "To completely validate the suitability of application changes, all changes should be tested in an environment that is fully reflective of production, to ensure there is no potential impact from environment deltas",
    "id": "app_deploy_testparity"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Build Environments",
    "title": "Are mocks/stubs used to test external dependencies in non-production environments?",
    "context": "",
    "recommendation": "The use of dependent services should be appropriately reflected in test environments",
    "id": "app_deploy_mocks"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Build Environments",
    "title": "Are releases to production gated by having it successfully deployed and tested in other environments?",
    "context": "",
    "recommendation": "It is recommended to have a staged deployment process which requires changes to have been validate in test environments first before they can hit production",
    "id": "app_deploy_gates"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Build Environments",
    "title": "Are feature flags used to test features before rolling them out to everyone?",
    "context": "",
    "recommendation": "To test new features quickly and without bigger risk, Feature flags are a technique to help frequently integrate code into a shared repository, even if incomplete. It allows for deployment decisions to be separated from release decisions([Feature Flags](https://docs.microsoft.com/en-us/azure/architecture/framework/devops/development#feature-flags))",
    "id": "app_deploy_featureflags"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Testing & Validation",
    "title": "Is the application tested for performance, scalability, and resiliency?",
    "context": "Performance Testing: Performance testing is the superset of both load and stress testing. The primary goal of performance testing is to validate benchmark behaviour for the application([Performance Testing](https://docs.microsoft.com/en-us/azure/architecture/checklist/dev-ops#testing))\nLoad Testing : Load testing validates application scalability by rapidly and/or gradually increasing the load on the application until it reaches a threshold/limit \nStress Testing : *Stress testing is a type of negative testing which involves various activities to overload existing resources and remove components to understand overall resiliency and how the application responds to issues",
    "recommendation": "",
    "children": [
      {
        "title": "When do you do test for performance, scalability, and resiliency?",
        "context": "Regular testing should be performed as part of each major change and if possible on a regular basis to validate existing thresholds, targets and assumptions, as well as ensuring the validity of the health model, capacity model and operational procedures",
        "recommendation": "",
        "id": ""
      },
      {
        "title": "Are any tests performed in production?",
        "context": "While the majority of testing should be performed within the testing and staging environments, it is often beneficial to also run a subset of tests against the production system",
        "recommendation": "",
        "id": ""
      },
      {
        "title": "Is the application tested with injected faults?",
        "context": "It is a common \"chaos monkey\" practice to verify the effectiveness of operational procedures using artificial faults. For example, taking dependencies offline (stopping API apps, shutting down VMs, etc.), restricting access (enabling firewall rules, changing connection strings, etc.) or forcing failover (database level, Front Door, etc.) is a good way to validate that the application is able to handle faults gracefully",
        "recommendation": "",
        "id": ""
      }
    ],
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Testing & Validation",
    "title": "Are smoke tests performed during application deployments?",
    "context": "Smoke tests are a lightweight way to perform high-level validation of changes. For instance, performing a ping test immediately after a deployment([Smoke Testing](https://docs.microsoft.com/en-us/azure/architecture/framework/devops/testing#smoke-testing))",
    "recommendation": "",
    "id": "app_depl_testing_smoketest"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Testing & Validation",
    "title": "When is integration testing performed?",
    "context": "Integration tests should be applied as part of the application deployment process, to ensure that different application components  interact with each other as they should. Integration tests typically take longer than smoke testing, and as a consequence occur at a latter stage of the deployment process so they are executed less frequently([Integration Testing](https://docs.microsoft.com/en-us/azure/architecture/framework/devops/testing#integration-testing)",
    "recommendation": "",
    "id": "app_depl_testing_when"
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Testing & Validation",
    "title": "Is unit testing performed to validate application functionality?",
    "context": "Unit tests are typically run by each new version of code committed into version control. Unit Tests should be extensive and quick to verify things like syntax correctness of application code, Resource Manager templates or Terraform configurations, that the code is following best practices, or that they produce the expected results when provided certain inputs([Unit Testing](https://docs.microsoft.com/en-us/azure/architecture/framework/devops/testing#unit-testing))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence",
      "reliability"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Testing & Validation",
    "title": "Are these tests automated and carried out periodically or on-demand?",
    "context": "Testing should be fully automated where possible and performed as part of the deployment lifecycle to validate the impact of all application changes. Additionally, manual explorative testing may also be conducted",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Testing & Validation",
    "title": "Are tests and test data regularly validated and updated to reflect necessary changes?",
    "context": "Tests and test data should be evaluated and updated after each major application change, update, or outage",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Testing & Validation",
    "title": "What happens when a test fails?",
    "context": "Failed tests should temporarily block a deployment and lead to a deeper analysis of what has happened and to either a refinement of the test or an improvement of the change that caused the test to fail",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Testing & Validation",
    "title": "Do you perform Business Continuity 'fire drills' to test regional failover scenarios?",
    "context": "Business Continuity 'fire drills' help to ensure operational readiness and validate the accuracy of recovery procedures ready for critical incidents",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Testing & Validation",
    "title": "What degree of security testing is performed?",
    "context": "Security and penetration testing, such as scanning for open ports or known vulnerabilities and exposed credentials, is vital to ensure overall security and also support operational effectiveness of the system",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "General",
    "title": "Are specific methodologies, like DevOps, used to structure the development and operations process?",
    "context": "The contraction of “Dev” and “Ops” refers to replacing siloed Development and Operations to create multidisciplinary teams that now work together with shared and efficient practices and tools. Essential DevOps practices include agile planning, continuous integration, continuous delivery, and monitoring of applications (from [docs.microsoft.com](https://docs.microsoft.com/en-us/azure/devops/learn/what-is-devops)).",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "General",
    "title": "Is the current development and operations process connected to a Service Management framework like ISO or ITIL?",
    "context": "[ITIL](https://en.wikipedia.org/wiki/ITIL) is a set of detailed [IT service management (ITSM)](https://en.wikipedia.org/wiki/IT_service_management) practices that can complement DevOps by providing support for products and services built and deployed using DevOps practices.",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "Roles & Responsibilities",
    "title": "Has the application been built and maintained in-house or by an external partner?",
    "context": "Exploring where technical delivery capabilities reside helps to qualify operational model boundaries",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "Roles & Responsibilities",
    "title": "Is there a separation between development and operations?",
    "context": "A true DevOps model positions the responsibility of operations with developers, but many customers do not fully embrace DevOps and maintain some degree of team separation between operations and development, either to enforce clear segregation of duties for regulated environments, or to share operations as a business function",
    "recommendation": "",
    "children": [
      {
        "title": "Does the development team own production deployments?",
        "context": "It is important to understand if developers are responsible for production deployments end-to-end, or if a handover point exists where responsibility is passed to an alternative operations team, potentially to ensure a strict segregation of duties such as Sarbanes-Oxley Act where developers cannot touch financial reporting systems",
        "recommendation": "",
        "id": ""
      },
      {
        "title": "How do development and operations teams collaborate to resolve production issues?",
        "context": "It is important to understand how operations and development teams collaborate to address operational issues, and what processes exist to support and structure this collaboration. Moreover, mitigating issues might require the involvement of different teams outside of development or operations, such as networking, and in some cases external parties as well. The processes to support this collaboration should also be understood",
        "recommendation": "",
        "id": ""
      },
      {
        "title": "Is the workload isolated to a single operations team?",
        "context": "The goal of workload isolation is to associate an application's specific resources to a team, so that the team can independently manage all aspects of those resources([Workload isolation](https://docs.microsoft.com/en-us/azure/architecture/framework/devops/app-design#workload-isolation))",
        "recommendation": "",
        "id": ""
      }
    ],
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "Roles & Responsibilities",
    "title": "Are any broader teams responsible for operational aspects of the application?",
    "context": "Different teams such as Central IT, Security, or Networking may be responsible for aspects of the application which are controlled centrally, such as a shared network virtual appliance (NVA).",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "Roles & Responsibilities",
    "title": "How are development priorities managed for the application?",
    "context": "It is important to understand how business features are prioritized relative to engineering fundamentals, especially if operations is a separate function",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "Roles & Responsibilities",
    "title": "Are manual approval gates or workflows required to release to production?",
    "context": "Even with an automated deployment process there might be a requirement for manual approvals to fulfil regulatory compliance, and it is important to understand who owns any gates that do exist",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "Roles & Responsibilities",
    "title": "Are tools or processes in place to grant access on a just in-time basis?",
    "context": "For example, Azure AD [Privileged Identity Management](https://docs.microsoft.com/en-us/azure/active-directory/privileged-identity-management/pim-configure) provides time-based and approval-based role activation to mitigate the risks of excessive, unnecessary, or misused access permissions on resources that you care about",
    "recommendation": "",
    "children": [
      {
        "title": "Does anyone have long-standing write-access to production environments?",
        "context": "Write-access to production systems should be limited to service principals and no user accounts have regular write-access",
        "recommendation": "",
        "id": ""
      }
    ],
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "Common Engineering Criteria",
    "title": "Is the choice and desired configuration of Azure services centrally governed or can the developers pick and choose?",
    "context": "Many customers govern service configuration through a catalogue of allowed services that developers and application owners must pick from",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "Common Engineering Criteria",
    "title": "Are tools and processes in place to govern available services, enforce mandatory operational functionality and ensure compliance?",
    "context": "Proper standards for naming, tagging, the deployment of specific configurations such as diagnostic logging, and the available set of services and regions is important to drive consistency and ensure compliance. Solutions like [Azure Policy](https://docs.microsoft.com/en-us/azure/governance/policy/overview) can help to enforce and assess compliance at-scale.",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "Common Engineering Criteria",
    "title": "Are standards, policies, restrictions and best practices defined as code?",
    "context": "Policy-as-Code provides the same benefits as Infrastructure-as-Code in regards to versioning, automation, documentation as well as encouraging consistency and reproducibility. Available solutions in the market are [Azure Policy](https://docs.microsoft.com/en-us/azure/governance/policy/overview) or [HashiCorp Sentinel](https://www.hashicorp.com/resources/introduction-sentinel-compliance-policy-as-code/).",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Does the application support multi-region deployments?",
    "context": "Multiple regions should be used for failover purposes in a disaster state, as part of either re-deployment, warm-spare active-passive, or hot-spare active-active strategies([Failover strategies](https://docs.microsoft.com/en-us/azure/availability-zones/az-overview#availability-zones))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Within a region is the application architecture designed to use Availability Zones?",
    "context": "Availability Zones can be used to optimise application availability within a region by providing datacenter level fault tolerance. However, the application architecture must not share dependencies between zones to use them effectively. It is also important to note that Availability Zones may introduce performance and cost considerations for applications which are extremely 'chatty' across zones given the implied physical separation between each zone and inter-zone bandwidth charges([Availability Zones](https://docs.microsoft.com/en-us/azure/availability-zones/az-overview#availability-zones))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Is component proximity required for application performance reasons?",
    "context": "If all or part of the application is highly sensitive to latency it may mandate component co-locality which can limit the applicability of multi-region and multi-zone strategies",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Can the application operate with reduced functionality or degraded performance in the presence of an outage?",
    "context": "Avoiding failure is impossible in the public cloud, and as a result applications require resilience to respond to outages and deliver reliability. The application should therefore be designed to operate even when impacted by regional, zonal, service or component failures across critical application scenarios and functionality",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Is the application designed to use managed services?",
    "context": "Azure managed services provide native resiliency capabilities to support overall application reliability, and where possible platform as a service offerings should be used to leverage these capabilities([Use managed services](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/managed-services))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Has the application been designed to scale-out?",
    "context": "Azure provides elastic scalability, however, applications must leverage a scale-unit approach to navigate service and subscription limits to ensure that individual components and the application as a whole can scale horizontally([Design to scale out](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/scale-out))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Is the application deployed across multiple Azure subscriptions?",
    "context": "Understanding the subscription landscape of the application and how components are organized within or across subscriptions is important when analyzing if relevant subscription limits or quotas can be navigated",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Failure Mode Analysis",
    "title": "Has pathwise analysis been conducted to identify key flows within the application?",
    "context": "Pathwise analysis can be used to decompose a complex application into key flows to which business impact can be attached. Frequently, these key flows can be used to identify business critical paths within the application to which reliability targets are most applicable",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Failure Mode Analysis",
    "title": "Have all fault-points and fault-modes been identified?",
    "context": "Fault-points describe the elements within an application architecture which are capable of failing, while fault-modes capture the various ways by which a fault-point may fail. To ensure an application is resilient to end-to-end failures, it is essential that all fault-points and fault-modes are understood and operationalized([Failure Mode Analysis for Azure applications](https://docs.microsoft.com/en-us/azure/architecture/resiliency/failure-mode-analysis))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Failure Mode Analysis",
    "title": "Have all single points of failure been eliminated?",
    "context": "A single point of failure describes a specific fault-point which if it where to fail would bring down the entire application. Single points of failure  introduce significant risk since any failure of this component will cause an application outage([Make all things redundant](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/redundancy))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Failure Mode Analysis",
    "title": "Have all 'singletons' been eliminated?",
    "context": "A 'singleton' describes a logical component within an application for which there can only ever be a single instance. It can apply to stateful architectural components or application code constructs. Ultimately, singletons introduce a significant risk by creating single points of failure within the application design",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Dependencies",
    "title": "Are all platform-level dependencies identified and understood?",
    "context": "The usage of platform level dependencies such as Azure Active Directory must also be understood to ensure that their availability and recovery targets align with that of the application",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Dependencies",
    "title": "Can the application operate in the absence of its dependencies?",
    "context": "If the application has strong dependencies which it cannot operate in the absence of, then the availability and recovery targets of these dependencies should align with that of the application itself. Effort should be taken to minimize dependencies to achieve control over application reliability([Minimize dependencies](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/minimize-coordination))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Dependencies",
    "title": "Is the lifecycle of the application decoupled from its dependencies?",
    "context": "If the application lifecycle is closely coupled with that of its dependencies it can limit the operational agility of the application, particularly where new releases are concerned",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Is an availability strategy defined? i.e. multi-geo, full/partial",
    "context": "An availability strategy should capture how the application remains available when in a failure state and should apply across all application components and the application deployment stamp as a whole such as via multi-geo scale-unit deployment approach",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Has a Business Continuity Disaster Recovery (BCDR) strategy been defined for the application and/or its key scenarios?",
    "context": "A disaster recovery strategy should capture how the application responds to a disaster situation such as a regional outage or the loss of a critical platform service, using either a re-deployment, warm-spare active-passive, or hot-spare active-active approach",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Capacity & Service Availability",
    "subCategory": "Service Availability",
    "title": "Are Azure services available in the required regions?",
    "context": "All Azure services and SKUs are not available within every Azure region, so it is important to understand if the selected regions for the application offer all of the required capabilities. Service availability also varies across sovereign clouds, such as China (\"Mooncake\") or USGov, USNat, and USSec clouds. In situations where capabilities are missing, steps should be taken to ascertain if a roadmap exists to deliver required services([Azure Products by Region](https://azure.microsoft.com/en-us/global-infrastructure/services/)).",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Capacity & Service Availability",
    "subCategory": "Service Availability",
    "title": "Are Azure Availability Zones available in the required regions?",
    "context": "Not all regions support Availability Zones today, so when assessing the suitability of availability strategy in relation to targets it is important to confirm if targeted regions also provide zonal support. All net new Azure regions will conform to the 3 + 0 datacenter design, and where possible existing regions will expand to provide support for Availability Zones([Regions that support Availability Zones in Azure](https://docs.microsoft.com/en-us/azure/availability-zones/az-region))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Capacity & Service Availability",
    "subCategory": "Service Availability",
    "title": "Are any preview services/capabilities required in production?",
    "context": "If the application has taken a dependency on preview services or SKUs then it is important to ensure that the level of support and committed SLAs are in alignment with expectations and that roadmap plans for preview services to go \nGenerally Available (GA) are understood \nPrivate Preview : SLAs do not apply and formal support is not generally provided \nPublic Preview : SLAs do not apply and formal support may be provided on a best-effort basis",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Capacity & Service Availability",
    "subCategory": "Service Availability",
    "title": "Are all APIs/SDKs validated against target runtime/languages for required functionality?",
    "context": "While there is a desire across Azure to achieve API/SDK uniformity for supported languages and runtimes, the reality is that capability deltas exist. For instance, not all CosmosDB APIs support the use of direct connect mode over TCP to bypass the platform HTTP gateway. It is therefore important to ensure that APIs/SDKs for selected languages and runtimes provide all of the required capabilities",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Capacity & Service Availability",
    "subCategory": "Capacity",
    "title": "Is there a capacity model for the application?",
    "context": "A capacity model should describe the relationships between the utilization of various components as a ratio, to capture when and how application components should scale-out. For instance, scaling the number of Application Gateway v2 instances may put excess pressure on downstream components unless also scaled to a degree. When modelling capacity for critical system components it is therefore recommended that an N+1 model be applied to ensure complete tolerance to transient faults, where n describes the capacity required to satisfy performance and availability requirements([Performance Efficiency - Capacity](https://docs.microsoft.com/en-us/azure/architecture/framework/scalability/capacity))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Capacity & Service Availability",
    "subCategory": "Capacity",
    "title": "Is the required capacity (initial and future growth) within Azure service scale limits and quotas?",
    "context": "Due to physical and logical resource constraints within the platform, Azure must apply limits and quotas to service scalability, which may be either hard or soft. The application should therefore take a scale-unit approach to navigate within service limits, and where necessary consider multiple subscriptions which are often the boundary for such limits. It is highly recommended that a structured approach to scale be designed up-front rather than resorting to a 'spill and fill' model([Azure subscription and service limits, quotas, and constraints](https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/azure-subscription-service-limits))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Capacity & Service Availability",
    "subCategory": "Capacity",
    "title": "Is the required capacity (initial and future growth) available within targeted regions?",
    "context": "While the promise of the cloud is infinite scale, the reality is that there are finite resources available and as a result situations can occur where capacity can be constrained due to overall demand. If the application requires a large amount of capacity or expects a significant increase in capacity then effort should be invested to ensure that desired capacity is attainable within selected region(s). For applications leveraging a recovery or active-passive based disaster recovery strategy, consideration should also be given to ensure suitable capacity exists in the secondary region(s) since a regional outage can lead to a significant increase in demand within a paired region due to other customer workloads also failing over. To help mitigate this, consideration should be given to pre-provisioning resources within the secondary region([Azure Capacity](https://aka.ms/AzureCapacity))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "Is the application stateless or stateful? If it is stateful, is the state externalized in a data store?",
    "context": "Stateless processes can easily be hosted across multiple compute instances to meet scale demands, as well as helping to reduce complexity and ensure high cacheability([Stateless web services](https://docs.microsoft.com/en-us/aspnet/aspnet/overview/developing-apps-with-windows-azure/building-real-world-cloud-apps-with-windows-azure/web-development-best-practices))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "Is the session state (if any) non-sticky and externalized to a data store?",
    "context": "Sticky session state limits application scalability because it is not possible to balance load. With sticky sessions all requests from a client must be sent to the same compute instance where the session state was initially created, regardless of the load on that compute instance. Externalizing session state allows for traffic to be evenly distributed across multiple compute nodes, with required state retrieved from the external data store([Avoid session state](https://docs.microsoft.com/en-us/aspnet/aspnet/overview/developing-apps-with-windows-azure/building-real-world-cloud-apps-with-windows-azure/web-development-best-practices#sessionstate))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Platform Availability",
    "subCategory": "Service SKU",
    "title": "Are all application platform services running in a HA configuration/SKU?",
    "context": "Azure application platform services offer resiliency features to support application reliability, though they may only be applicable at a certain SKU. For instance, Service Bus Premium SKU provides predictable latency and throughput to mitigate noisy neighbor scenarios, as well as the ability to automatically scale and replicate metadata to another Service Bus instance for failover purposes([Azure Service Bus Premium SKU](https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-premium-messaging)",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Platform Availability",
    "subCategory": "Compute Availability",
    "title": "Is the application platform deployed across multiple regions?",
    "context": "The ability to respond to disaster scenarios for overall compute platform availability and application resiliency is dependant on the use of multiple regions or other deployment locations",
    "recommendation": "",
    "children": [
      {
        "title": "Are paired regions used?",
        "context": "Paired regions exist within the same geography and provide native replication features for recovery purposes, such as Geo-Redundant Storage (GRS) asynchronous replication. In the event of planned maintenance, updates to a region will be performed sequentially only([Business continuity with Azure Paired Regions](https://docs.microsoft.com/en-us/azure/best-practices-availability-paired-regions))",
        "recommendation": "",
        "id": ""
      }
    ],
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Platform Availability",
    "subCategory": "Compute Availability",
    "title": "Is the underlying application platform service Availability Zone aware?",
    "context": "Platform services that can leverage Availability Zones are deployed in either a zonal manner within a particular zone, or in a zone-redundant configuration across multiple zones([Building solutions for high availability using Availability Zones](https://docs.microsoft.com/en-us/azure/architecture/high-availability/building-solutions-for-high-availability))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Platform Availability",
    "subCategory": "Compute Availability",
    "title": "Is the application hosted across 2 or more application platform nodes?",
    "context": "To ensure application platform reliability, it is vital that the application be hosted across at least two nodes to ensure there are no single points of failure. Ideally An n+1 model should be applied for compute availability where n is the number of instances required to support application availability and performance requirements. It is important to note that the higher SLAs provided for virtual machines and associated related platform services, require at least two replica nodes deployed to either an Availability Set or across two or more Availability Zones([SLA for Virtual Machines](https://azure.microsoft.com/en-us/support/legal/sla/virtual-machines/v1_9/))",
    "recommendation": "",
    "children": [
      {
        "title": "Does the application platform use Availability Zones or Availability Sets?",
        "context": "An Availability Set (AS) is a logical construct to inform Azure that it should distribute contained virtual machine instances across multiple fault and update domains within an Azure region. Availability Zones (AZ) elevate the fault level for virtual machines to a physical datacenter by allowing replica instances to be deployed across multiple datacenters within an Azure region. While zones provide greater resiliency than sets, there are performance and cost considerations where applications are extremely 'chatty' across zones given the implied physical separation and inter-zone bandwidth charges. Ultimately, Azure Virtual Machines and Azure PaaS services, such as Service Fabric and Azure Kubernetes Service (AKS) which use virtual machines underneath, can leverage either AZs or an AS to provide application resiliency within a region([Business continuity with data resiliency](https://azurecomcdn.azureedge.net/cvt-27012b3bd03d67c9fa81a9e2f53f7d081c94f3a68c13cdeb7958edf43b7771e8/mediahandler/files/resourcefiles/azure-resiliency-infographic/Azure_resiliency_infographic.pdf))",
        "recommendation": "",
        "id": ""
      }
    ],
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Application Platform Availability",
    "subCategory": "Compute Availability",
    "title": "How is the client traffic routed to the application in the case of region, zone or network outage?",
    "context": "In the event of a major outage, client traffic should be routable to application deployments which remain available across other regions or zones. This is ultimately where cross-premises connectivity and global load balancing should be used, depending on whether the application is internal and/or external facing. Services such as Azure Front Door, Azure Traffic Manager, or third-party CDNs can route traffic across regions based on application health solicited via health probes([Traffic Manager endpoint monitoring](https://docs.microsoft.com/en-us/azure/traffic-manager/traffic-manager-monitoring))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Data Platform Availability",
    "subCategory": "Service SKU",
    "title": "Are all data and storage services running in a HA configuration/SKU?",
    "context": "Azure data platform services offer resiliency features to support application reliability, though they may only be applicable at a certain SKU. For instance, Azure SQL Database Business Critical SKUs, or Azure Storage Zone Redundant Storage (ZRS) with three synchronous replicas spread across AZs",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Data Platform Availability",
    "subCategory": "Consistency",
    "title": "How does CAP theorem apply to the data platform and key application scenarios?",
    "context": "CAP theorem proves that it is impossible for a distributed data store to simultaneously provide more than two guarantees across 1) Consistency (every read receives the most recent write or an error), 2) Availability (very request receives a non-error response, without the guarantee that it contains the most recent write), and 3) Partition tolerance (a system continues to operate despite an arbitrary number of transactions being dropped or delayed by the network between nodes). Determining which of these guarantees are most important in the context of application requirements is critical",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Data Platform Availability",
    "subCategory": "Consistency",
    "title": "Are data types categorized by data consistency requirements?",
    "context": "Data consistency requirements, such as strong or eventual consistency, should be understood for all data types and used to inform data grouping and categorization, as well as what data replication/synchronization strategies can be considered to meet application reliability targets",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Data Platform Availability",
    "subCategory": "Replication and Redundancy",
    "title": "Is data replicated across paired regions and/or Availability Zones",
    "context": "Replicating data across zones or paired regions supports application availability objectives to limit the impact of failure scenarios",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Data Platform Availability",
    "subCategory": "Replication and Redundancy",
    "title": "Is data backed-up to zone-redundant or geo-redundant storage?",
    "context": "The ability to restore data from a backup is essential when recovering from data corruption situations as well as failure scenarios. To ensure sufficient redundancy and availability for zonal and regional failure scenarios, such backups should be stored across zones and/or regions",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Data Platform Availability",
    "subCategory": "Replication and Redundancy",
    "title": "Has a data restore process been defined and tested to ensure a consistent application state?",
    "context": "Regular testing of the data restore process promotes operational excellence and confidence in the ability to recover data in alignment with defined recovery objectives for the application",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Data Platform Availability",
    "subCategory": "Replication and Redundancy",
    "title": "How is application traffic routed to data sources in the case of region, zone, or network outage?",
    "context": "Understanding the method used to route application traffic to data sources in the event of a major failure event is critical to identify whether failover processes will meet recovery objectives. Many Azure data platform services offer native reliability capabilities to handle major failures, such as Cosmos DB Automatic Failover or Azure SQL DB Active Geo-Replication. However, it is important to note that some capabilities such as Azure Storage RA-GRS and Azure SQL DB Active Geo-Replication require application-side failover to alternate endpoints in some failure scenarios, so application logic should be developed to handle these scenarios",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Connectivity",
    "title": "Is a global load balancer used to distribute traffic and/or failover across regions?",
    "context": "Azure Front Door, Azure Traffic Manager, or third-party CDN services can be used to direct inbound requests to external-facing application endpoints deployed across multiple regions. It is important to note that Traffic Manager is a DNS based load balancer, so failover must wait for DNS propagation to occur. A sufficiently low TTL (Time To Live) value should be used for DNS records, though not all ISPs may honor this. For application scenarios requiring transparent failover, Azure Front Door should be used([Disaster Recovery using Azure Traffic Manager](https://docs.microsoft.com/en-us/azure/networking/disaster-recovery-dns-traffic-manager))([Azure Frontdoor routing architecture](https://docs.microsoft.com/en-us/azure/frontdoor/front-door-routing-architecture))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Connectivity",
    "title": "For cross-premises connectivity (ExpressRoute or VPN) are there redundant connections from different locations?",
    "context": "At least two redundant connections should be established across two or more Azure regions and peering locations to ensure there are no single points of failure. An active/active load-shared configuration provides path diversity and promotes availability of network connection paths([Cross-network connectivity](https://docs.microsoft.com/azure/expressroute/cross-network-connectivity))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Connectivity",
    "title": "Has a failure path been simulated to ensure connectivity is available over alternative paths?",
    "context": "The failure of a connection path onto other connection paths should be tested to validate connectivity and operational effectiveness. Using Site-to-Site VPN connectivity as a backup path for ExpressRoute provides an additional layer of network resiliency for cross-premises connectivity([Using site-to-site VPN as a backup for ExpressRoute private peering](https://docs.microsoft.com/azure/expressroute/use-s2s-vpn-as-backup-for-expressroute-privatepeering))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Connectivity",
    "title": "Have all single points of failure been eliminated from the data path (on-premises and Azure)?",
    "context": "Single-instance Network Virtual Appliances (NVAs), whether deployed in Azure or within an on-premises datacenter, introduce significant connectivity risk([Deploy highly available network virtual appliances](https://docs.microsoft.com/azure/architecture/reference-architectures/dmz/nva-ha)",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Zone-Aware Services",
    "title": "Are ExpressRoute/VPN zone-redundant Virtual Network Gateways used?",
    "context": "Zone-redundant virtual network gateways distribute gateway instances across Availability Zones to improve reliability and ensure availability during failure scenarios impacting a datacenter within a region([Zone-redundant Virtual Network Gateways](https://docs.microsoft.com/en-us/azure/vpn-gateway/about-zone-redundant-vnet-gateways))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Zone-Aware Services",
    "title": "If used, is Azure Application Gateway v2 deployed in a zone-redundant configuration?",
    "context": "Azure Application Gateway v2 can be deployed in a zone-redundant configuration to deploy gateway instances across zones for improved reliability and availability during failure scenarios impacting a datacenter within a region([Zone-redundant Application Gateway v2](https://docs.microsoft.com/en-us/azure/application-gateway/application-gateway-autoscaling-zone-redundant))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Zone-Aware Services",
    "title": "Is Azure Load Balancer Standard being used to load-balance traffic across Availability Zones?",
    "context": "Azure Load Balancer Standard is zone-aware to distribute traffic across Availability Zones and can also be configured in a zone-redundant configuration to improve reliability and ensure availability during failure scenarios impacting a datacenter within a region([Standard Load Balancer and Availability Zones](https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-standard-availability-zones))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Zone-Aware Services",
    "title": "Are health probes configured for Azure Load Balancer(s)/Azure Application Gateway(s)?",
    "context": "Health probes allow Azure Load Balancers to assess the health of backend endpoints to prevent traffic from being sent to unhealthy instances([Load Balancer health probes](https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-custom-probe-overview))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Zone-Aware Services",
    "title": "Do health probes assess critical application dependencies?",
    "context": "Custom health probes should be used to assess overall application health including downstream components and dependent services, such as APIs and datastores, so that traffic is not sent to backend instances that cannot successfully process requests due to dependency failures([Health Endpoint Monitoring Pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/health-endpoint-monitoring))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "App Performance",
    "title": "Does the application logic handle exceptions and errors using resiliency patterns?",
    "context": "Programming paradigms such as retry patterns, request timeouts, and circuit breaker patterns can improve application resiliency by automatically recovering from transient faults([Error handling for resilient applications](https://docs.microsoft.com/en-us/azure/architecture/framework/resiliency/app-design-error-handling))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "App Performance",
    "title": "Does the application require long running TCP connections?",
    "context": "If an application is initiating many outbound TCP or UDP connections it may exhaust all available ports leading to SNAT port exhaustion and poor application performance. Long-running connections exacerbate this risk by occupying ports for sustained durations. Effort should be taken to ensure that the application can scale within the port limits of the chosen application hosting platform([Managing SNAT port exhaustion](https://docs.microsoft.com/en-us/azure/load-balancer/troubleshoot-outbound-connection#snatexhaust))    ",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "Data Size/Growth",
    "title": "Are target data sizes and associated growth rates calculated per scenario or service?",
    "context": "Scale limits and recovery options should be assessed in the context of target data sizes and growth rates to ensure suitable capacity exists",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "Data Size/Growth",
    "title": "Are there any mitigation plans defined in case data size exceeds limits?",
    "context": "Mitigation plans such as purging or archiving data can help the application to remain available in scenarios where data size exceeds expected limits",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "Data Latency and Throughput",
    "title": "Are latency targets defined, tested, and validated for key scenarios?",
    "context": "Latency targets, which are commonly defined as first byte in to last byte out, should be defined and measured for key application scenarios, as well as each individual component, to validate overall application performance and health",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "Data Latency and Throughput",
    "title": "Are throughput targets defined, tested, and validated for key scenarios?",
    "context": "Throughput targets, which are commonly defined in terms of IOPS, MB/s and Block Size, should be defined and measured for key application scenarios, as well as each individual component, to validate overall application performance and health. Available throughput typically varies based on SKU, so defined targets should be used to inform the use of appropriate SKUs",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "Network Throughput and Latency",
    "title": "Are there any components/scenarios that are very sensitive to network latency?",
    "context": "Components or scenarios that are sensitive to network latency may indicate a need for co-locality within a single Availability Zone or even closer using Proximity Placement Groups with Accelerated Networking enabled([Proximity Placement Groups](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/co-location#proximity-placement-groups))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "Network Throughput and Latency",
    "title": "Have gateways (ExpressRoute or VPN) been sized accordingly to the expected cross-premises network throughput?",
    "context": "Azure Virtual Network Gateways throughput varies based on SKU. Gateways should therefore be sized according to required throughput([VPN Gateway SKUs](https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpn-gateway-settings#gwsku))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "Network Throughput and Latency",
    "title": "Does the application require dedicated bandwidth?",
    "context": "Applications with stringent throughput requirements may require dedicated bandwidth to remove the risks associated with noisy neighbor scenarios",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "Network Throughput and Latency",
    "title": "If NVAs are used, has expected throughput been tested?",
    "context": "Maximum potential throughput for third-party NVA solutions is based on a combination of the leveraged VM SKU size, support for Accelerated Networking, support for HA ports, and more generally the NVA technology used. Expected throughput should be tested to ensure optimal performance, however, it is best to confirm throughput requirements with the NVA vendor directly",
    "recommendation": "",
    "children": [
      {
        "title": "Is autoscaling enabled based on throughput",
        "context": "Autoscaling capabilities can vary between NVA solutions, but ultimately help to mitigate common bottle-neck situations",
        "recommendation": "",
        "id": ""
      }
    ],
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "Elasticity",
    "title": "Can the application scale horizontally in response to changing load?",
    "context": "A scale-unit approach should be taken to ensure that each application component and the application as a whole can scale effectively in response to changing demand. A robust capacity model should be used to define when and how the application should scale",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "Elasticity",
    "title": "Has the time to scale in/out been measured?",
    "context": "Time to scale-in and scale-out can vary between Azure services and instance sizes and should be assessed to determine if a certain amount of pre-scaling is required to handle scale requirements and expected traffic patterns, such as seasonal load variations",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Scalability & Performance",
    "subCategory": "Elasticity",
    "title": "Is autoscaling enabled and integrated within Azure Monitor?",
    "context": "Autoscaling can be leveraged to address unanticipated peak loads to help prevent application outages caused by overloading",
    "recommendation": "",
    "children": [
      {
        "title": "Has autoscaling been tested under sustained load?",
        "context": "The scaling on any single component may have an impact on downstream application components and dependencies. Autoscaling should therefore be tested regularly to help inform and validate a capacity model describing when and how application components should scale",
        "recommendation": "",
        "id": ""
      }
    ],
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Identity and Access",
    "title": "Is the identity provider and associated dependencies highly available?",
    "context": "It is important to confirm that the identity provider (e.g. Azure AD, AD, or ADFS) and its dependencies (e.g. DNS and network connectivity to the identity provider) are designed in a way and provide an SLA/SLO that aligns with application availability targets",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Identity and Access",
    "title": "Has role-based and/or resource-based authorization been configured within Azure AD?",
    "context": "Role-based and resource-based authorization are common approaches to authorize users based on required permission scopes([Role-based and resource-based authorization](https://docs.microsoft.com/en-us/azure/architecture/multitenant-identity/authorize))",
    "recommendation": "",
    "children": [
      {
        "title": "Does the application write-back to Azure AD?",
        "context": "The Azure AD SLA includes authentication, read, write, and administrative actions.  In many cases, applications only require authentication and read access to Azure AD, which aligns with a much higher operational availability due to geographically distributed read replicas([Azure AD Architecture](https://docs.microsoft.com/en-us/azure/active-directory/fundamentals/active-directory-architecture))",
        "recommendation": "",
        "id": ""
      },
      {
        "title": "Are authentication tokens cached and encrypted for sharing across web servers?",
        "context": "Application code should first try to get tokens silently from a cache before attempting to acquire a token from the identity provider, to optimise performance and maximize availability([Acquire and cache tokens](https://docs.microsoft.com/en-us/azure/active-directory/develop/msal-acquire-cache-tokens))",
        "recommendation": "",
        "id": ""
      }
    ],
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Identity and Access",
    "title": "Are Azure AD emergency access accounts and processes defined for recovering from identity failures?",
    "context": "The impact of no administrative access can be mitigated by creating two or more emergency access accounts([Emergency Access accounts in Azure AD](https://docs.microsoft.com/en-us/azure/active-directory/users-groups-roles/directory-emergency-access))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Security Center",
    "title": "Is Azure Security Center Standard tier enabled for all subscriptions and reporting to centralized workspaces? Also, is automatic provisioning enabled for all subscriptions? ([Security Center Data Collection](https://docs.microsoft.com/en-us/azure/security-center/security-center-enable-data-collection))",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Security Center",
    "title": "Is Azure Security Center's Secure Score being formally reviewed and improved on a regular basis? ([Security Center Secure Score](https://docs.microsoft.com/en-us/azure/security-center/secure-score-security-controls))",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Security Center",
    "title": "Are contact details set in security center to the appropriate email distribution list? ([Security Center Contact Details](https://docs.microsoft.com/en-us/azure/security-center/security-center-provide-security-contact-details))",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Network Security",
    "title": "Are all external application endpoints secured?",
    "context": "External application endpoints should be protected against common attack vectors, such as Denial of Service (DoS) attacks like Slowloris, to prevent potential application downtime due to malicious intent. Azure native technologies such as Azure Firewall, Application Gateway/Azure Front Door WAF, and DDoS Protection Standard Plan can be used to achieve requisite protection([Azure DDoS Protection](https://docs.microsoft.com/en-us/azure/virtual-network/ddos-protection-overview))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Network Security",
    "title": "Is communication to Azure PaaS services secured using VNet Service Endpoints or Private Link?",
    "context": "Service Endpoints and Private Link can be leveraged to restrict access to PaaS endpoints from only authorized virtual networks, effectively mitigating data intrusion risks and associated impact to application availability. Service Endpoints provide service level access to a PaaS service, while Private Link provides direct access to a specific PaaS resource to mitigate data exfiltration risks (e.g. malicious admin scenarios)",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Network Security",
    "title": "If data exfiltration concerns exist for services where Private Link is not yet supported, is filtering via Azure Firewall or an NVA being used?",
    "context": "NVA solutions and Azure Firewall (for supported protocols) can be leveraged as a reverse proxy to restrict access to only authorized PaaS services for services where Private Link is not yet supported([Azure Firewall](https://docs.microsoft.com/en-us/azure/firewall/features))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Network Security",
    "title": "Are Network Security Groups (NSGs) being used?",
    "context": "If NSGs are being used to isolate and protect the application, the rule set should be reviewed to confirm that required services are not unintentionally blocked([Azure Platform Considerations for NSGs](https://docs.microsoft.com/en-us/azure/virtual-network/security-overview#azure-platform-considerations))",
    "recommendation": "",
    "children": [
      {
        "title": "Are NSG flow logs being collected?",
        "context": "NSG flow logs should be captured and analyzed to monitor performance and security([Why use NSG flow logs](https://docs.microsoft.com/en-us/azure/network-watcher/network-watcher-nsg-flow-logging-overview#why-use-flow-logs))",
        "recommendation": "",
        "id": ""
      }
    ],
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Monitoring and Measurement",
    "title": "Is white-box monitoring used to instrument the application with semantic logs and metrics?",
    "context": "Application level metrics and logs, such as current memory consumption or request latency, should be collected from the application to inform a health model and detect/predict issues([Instrumenting an application with Application Insights](https://docs.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Monitoring and Measurement",
    "title": "Is the application instrumented to measure the customer experience?",
    "context": "Effective instrumentation is vital to detecting and resolving performance anomalies that can impact customer experience and application availability([Monitor performance](https://docs.microsoft.com/en-us/azure/azure-monitor/app/web-monitor-performance))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Monitoring and Measurement",
    "title": "Is the application instrumented to track calls to dependent services?",
    "context": "Dependency tracking and measuring the duration/status of dependency calls is vital to measuring overall application health and should be used to inform a health model for the application([Dependency Tracking](https://docs.microsoft.com/en-us/azure/azure-monitor/app/asp-net-dependencies))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Monitoring and Measurement",
    "title": "Is black-box monitoring used to measure platform services and the resulting customer experience?",
    "context": "Black-box monitoring tests externally visible application behavior without knowledge of the internals of the system. This is a common approach to measuring customer-centric SLIs/SLOs/SLAs([Azure Monitor Reference](https://docs.microsoft.com/en-us/azure/azure-monitor/app/monitor-web-app-availability))",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Monitoring and Measurement",
    "title": "Are there known gaps in application observability that led to missed incidents and/or false positives?",
    "context": "What you cannot see, you cannot measure. What you cannot measure, you cannot improve",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Monitoring and Measurement",
    "title": "Are error budgets used to track service reliability?",
    "context": "An error budget describes the maximum amount of time that the application can fail without consequence, and is typically calculated as 1-SLA. For example, if the SLA specifies that the application will function 99.99% of the time before the business has to compensate customers, the error budget is 52 minutes and 35 seconds per year. Error budgets are a device to encourage development teams to minimize real incidents and maximize innovation by taking risks within acceptable limits, given teams are free to ‘spend’ budget appropriately",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Monitoring and Measurement",
    "title": "Is there an policy that dictates what will happen when the error budget has been exhausted?",
    "context": "If the application error budget has been met or exceeded and the application is operating at or below the defined SLA, a policy may stipulate that all deployments are frozen until they reduce the number of errors to a level that allows deployments to proceed",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "reliability"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Alerting",
    "title": "Do all alerts require an immediate response from an on-call engineer?",
    "context": "Alerts only deliver value if they are actionable and effectively prioritized by on-call engineers through defined operational procedures",
    "recommendation": "",
    "id": ""
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Threat Analysis",
    "title": "Does the organization identify the highest severity threats to this workload via threat modeling?",
    "recommendation": "",
    "id": "application_design_1988",
    "context": "Threat modeling is an engineering technique which can be used to help identify threats, attacks, vulnerabilities and countermeasures that could affect an application. Threat modeling consists of: defining security requirements, identifying threats, mitigating threats, validating threat mitigation. Microsoft uses [STRIDE](https://docs.microsoft.com/en-us/azure/security/develop/threat-modeling-tool-threats) for threat modeling.  This might be the right time to talk through the STRIDE methodology and then the tools available to help them with Threat Modeling.  There are tools like [Microsoft Threat Modeling Tool](https://docs.microsoft.com/azure/security/develop/threat-modeling-tool-getting-started) which can help.Determine if they understand the attack vectors of their solution with this question. Get them to discuss the defense in depth that they have around the identified threats and how they are detecting, protecting, and responding to a potential attack. Try to uncover how they identified the threats and communicated those to all interested parties or if rather are hoping no one finds out. This question should set the stage for the audience that needs to be involved and the topics that will be discussed throughout the assessment."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Threat Analysis",
    "title": "How are threats addressed once found?",
    "recommendation": "",
    "id": "application_design_9104",
    "context": "The threat modeling tool will produce a report of all the threats identified. This report is typically uploaded into a tracking tool or work items that can be validated and addressed by the developers. Cyber security teams can also use the report to determine attack vectors during a penetration test.  As new features are added to the solution, the threat model should be updated and integrated into the code management process.  If a security issue is found, there should be a process to triage the issue into the next release cycle or a faster release, depending on the severity.  Try to understand what process they use, if any, to prioritize security fixes."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Threat Analysis",
    "title": "How long does it typically take to deploy a security fix into production?",
    "recommendation": "",
    "id": "application_design_7087",
    "context": "Get an understanding of how the customer is updating when a security vulnerability is discovered in their software. Get them to talk through the process and tools, approvals, who they make aware and if they have executive sponsorship to bypass lengthy processes when it comes to security. How serious are they about security updates?"
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Security Criteria & Data Classification",
    "title": "How do you monitor and maintain your compliance?",
    "recommendation": "",
    "id": "application_design_6814",
    "context": "Find out how they make sure they maintain compliance as the Azure Platform evolves and they update their application. Are there things preventing them from adopting new features in the platform because it will knock them out of compliance?"
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Security Criteria & Data Classification",
    "title": "How often do you have internal and external audits?",
    "recommendation": "",
    "id": "application_design_2263",
    "context": "Determine the process the customer uses for auditing the solution. Is it done internally, external, or both. How are findings reflected back to the application? Is everyone aware of the audit and involved or is it done in a silo. This will help reduce the firefighting mentality when there is a finding and stress of performing updates."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Dependencies, frameworks and libraries",
    "title": "Does the application team maintain a list frameworks and libraries?",
    "recommendation": "",
    "id": "application_design_9273",
    "context": "As part of the application inventory the application team should maintain a framework and library list, along with versions in use."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Dependencies, frameworks and libraries",
    "title": "Are frameworks and library updates included into the application lifecycle?",
    "recommendation": "",
    "id": "application_design_6294",
    "context": "Application frameworks are frequently provided with updates (e.g. security), released by the vendor or communities. Critical and important security patches need to be prioritized."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Are errors and exceptions handled properly without exposing information to users?",
    "recommendation": "",
    "id": "application_design_2397",
    "context": "Providing unnecessary information to end users in case of application failure should be avoided. Revealing detailed error information (call stack, SQL queries, out of range errors...) can provide attackers with valuable information about the internals of the application. Error handlers should make the application fail gracefully and log the error."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Application Design",
    "subCategory": "Design",
    "title": "Is platform-specific information removed from server-client communication?",
    "recommendation": "",
    "id": "application_design_2599",
    "context": "Information revealing the application platform, such as HTTP banners containing framework information (\"`X-Powered-By`\", \"`X-ASPNET-VERSION`\"), are commonly used by malicious actors when mapping attack vectors of the application. HTTP headers, error messages, website footers etc. should not contain information about the application platform. Azure CDN or Cloudflare can be used to separate the hosting platform from end users, Azure API Management offers [transformation policies](https://docs.microsoft.com/azure/api-management/api-management-transformation-policies) that allow to modify HTTP headers and remove sensitive information."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "Are Azure policies used to control the configuration of the solution resources?",
    "recommendation": "",
    "id": "operational_procedures_8927",
    "context": "Azure Policy should be used to deploy desired settings where applicable. Azure resources should be blocked that do not meet the proper security requirements defined during service enablement."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Application Level Monitoring",
    "title": "How is security monitored in the application context?",
    "recommendation": "",
    "id": "health_modelling_5166",
    "context": "Organization is monitoring the security posture across workloads and central SecOps team is monitoring security-related telemetry data and investigating security breaches. Communication, investigation and hunting activities need to be aligned with the application team."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Application Level Monitoring",
    "title": "Does the organization actively monitor identity related risk events related to potentially compromised identities?",
    "recommendation": "",
    "id": "health_modelling_8539",
    "context": "Most security incidents take place after an attacker initially gains access using a stolen identity. These identities can often start with low privileges, but attackers then use that identity to traverse laterally and gain access to more privileged identities. This repeats as needed until the attacker controls access to the ultimate target data or systems. Reported risk events for Azure AD can be viewed in Azure AD reporting, or Azure AD Identity Protection. Additionally, the Identity Protection risk events API can be used to programmatically access identity related security detections using Microsoft Graph."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Application Level Monitoring",
    "title": "Is Personally identifiable information (PII) detected and removed/obfuscated automatically?",
    "recommendation": "",
    "id": "health_modelling_905",
    "context": "Extra care should be take around logging of sensitive application areas. PII (contact information, payment information etc.) should not be stored in any application logs and protective measures should be applied (such as obfuscation). Machine learning tools like [Cognitive Search PII detection](https://docs.microsoft.com/azure/search/cognitive-search-skill-pii-detection) can help with this."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Health Modelling",
    "subCategory": "Auditing",
    "title": "Is access to the control plane and data plane of the application periodically reviewed?",
    "recommendation": "",
    "id": "health_modelling_9112",
    "context": "As people in the organization and on the project change, it is crucial to make sure that only the right people have access to the application infrastructure. Auditing and reviewing the access control reduces the attack vector to the application. Azure control plane depends on Azure AD and access reviews are often centrally performed often as part of internal or external audit activities. For the application specific access it is recommended to do the same at least twice a year."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Patch & Update Process (PNU)",
    "title": "Does the organization reduce the count and potential severity of security vulnerabilities for this workload by implementing security practices and tools during the development lifecycle? [Develop Secure Applications on Azure whitepaper](https://azure.microsoft.com/resources/develop-secure-applications-on-azure/)",
    "recommendation": "",
    "id": "operational_procedures_9083",
    "context": "Security vulnerabilities can result in an application disclosing confidential data, allowing criminals to alter data/records, or the data/application becoming unavailable for use by customers and employees. Applications will almost always contain logic errors, so it is important to discover, evaluate, and correct them to avoid damage to the organization’s reputation, revenue, or margins. This is made easier by discovering these vulnerabilities in the early stages of the development cycle."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Incident Response",
    "title": "Are operational processes for incident response defined and tested?",
    "recommendation": "",
    "id": "operational_procedures_663",
    "context": "Actions executed during an incident and response investigation could impact application availability or performance. It is recommended to define these processes and align them with the responsible (and in most cases central) SecOps team. The impact of such an investigation on the application has to be analyzed."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Incident Response",
    "title": "Are there playbooks built to help incident responders quickly understand the application and components to do an investigation?",
    "recommendation": "",
    "id": "operational_procedures_9578",
    "context": "Incident responders are part of a central SecOps team and need to understand security insights of an application. Playbooks can help to understand the security concepts and cover the typical investigation activities."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Separation of duties",
    "title": "Does the application team have a clear view on responsibilities and individual/group access levels?",
    "recommendation": "",
    "id": "identity__access_control_6599",
    "context": "Application roles and responsibility model need to be defined covering the different access level of each operational function (e.g publish production release, access customer data, manipulate database records). It's in the interest of the application team to include central functions (e.g. SecOps, NetOps, IAM) into this view."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Separation of duties",
    "title": "Has role-based and/or resource-based authorization been configured within Azure AD?",
    "recommendation": "",
    "id": "identity__access_control_8031",
    "context": "Role-based and resource-based authorization are common approaches to authorize users based on required permission scopes. [Role-based and resource-based](https://docs.microsoft.com/azure/architecture/multitenant-identity/authorize)"
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Separation of duties",
    "title": "Are authentication tokens cached securely and encrypted when sharing across web servers?",
    "recommendation": "",
    "id": "identity__access_control_8946",
    "context": "Application code should first try to get tokens silently from a cache before attempting to acquire a token from the identity provider, to optimise performance and maximize availability. Tokens should be stored securely and handled as any other credentials. When there's a need to share tokens across application servers (instead of each server acquiring and caching their own) encryption should be used. [Acquire and cache tokens](https://docs.microsoft.com/azure/active-directory/develop/msal-acquire-cache-tokens)"
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Separation of duties",
    "title": "Are there any processes and tools leveraged to manage privileged activities?",
    "recommendation": "",
    "id": "identity__access_control_8652",
    "context": "Zero-trust principle comes with the requirement of no standing access to an environment. Native and 3rd party solution can be used to elevate access permissions for at least highly privileged if not all activities. [Azure AD Privileged Identity Management](https://docs.microsoft.com/azure/active-directory/privileged-identity-management/pim-configure) (Azure AD PIM) is the recommended and Azure native solution."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Control-plane RBAC",
    "title": "Is the application infrastructure protected with RBAC (role-based access control)?",
    "recommendation": "",
    "id": "identity__access_control_5609",
    "context": "RBAC provides the necessary tools to maintain separation of concerns when it comes to accessing the application infrastructure. Aligned with the [separation of duties](#separation-of-duties) section, users should have only the minimal set of permissions. Examples: \"Developers can't access production infrastructure.\", \"Only the SecOps team can read and manage Key Vault secrets.\", \"Project A team can access and manage Resource Group A and all resources within.\""
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Control-plane RBAC",
    "title": "Are there resource locks applied on critical parts of the infrastructure?",
    "recommendation": "",
    "id": "identity__access_control_270",
    "context": "To prevent deleting or modifying resources, Azure offers the locking functionality where only specific roles and users with permissions are able to delete/modify resources. Locks can be used on critical parts of the infrastructure, but special care needs to be taken in the DevOps process - modification locks can sometimes block automation."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Control-plane RBAC",
    "title": "Is there a direct access to the application infrastructure through Azure Portal, Command-line Interface (CLI) or REST API?",
    "recommendation": "",
    "id": "identity__access_control_6070",
    "context": "While it is recommended to deploy application infrastructure via automation and CI/CD. To maximize application autonomy and agility, restrictive access control need be balanced on less critical development and test environments."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Control-plane RBAC",
    "title": "Are CI/CD pipeline roles clearly defined and permissions set?",
    "recommendation": "",
    "id": "identity__access_control_855",
    "context": "Azure DevOps offers pre-defined roles which can be assigned to individual users of groups. Using them properly can make sure that for example only users responsible for production releases are able to initiate the process and that only developers can access the source code. Variable groups often contain sensitive configuration information and can be protected as well."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Authentication and authorization",
    "title": "How is the application authenticated when communicating with Azure platform services?",
    "recommendation": "",
    "id": "identity__access_control_3991",
    "context": "Try to avoid authentication with keys (connection strings, API keys etc.) and always prefer Managed Identities (formerly also known as Managed Service Identity, MSI). Managed identities enable Azure Services to authenticate to each other without presenting explicit credentials via code. Typical use case is a Web App accessing Key Vault credentials or a Virtual Machine accessing SQL Database. [Managed identities](https://docs.microsoft.com/azure/active-directory/managed-identities-azure-resources/)"
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Authentication and authorization",
    "title": "What kind of authentication is required by application APIs?",
    "recommendation": "",
    "id": "identity__access_control_2493",
    "context": "API URLs used by client applications are exposed to attackers (JavaScript code on a website can be viewed, mobile application can be decompiled and inspected) and should be protected. For internal APIs, requiring authentication can increase the difficulty of lateral movement if an attacker obtains network access. Typical mechanisms include API keys, authorization tokens, IP restrictions or Azure Managed identities."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Authentication and authorization",
    "title": "How is user authentication handled in the application?",
    "recommendation": "",
    "id": "identity__access_control_9416",
    "context": "If possible, applications should utilize Azure Active Directory or other managed identity providers (such as Microsoft Account, Azure B2C...) to avoid managing user credentials with custom implementation. Modern protocols like OAuth 2.0 use token-based authentication with limited timespan, identity providers offer additional functionality like multi-factor authentication, password reset etc."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Authentication and authorization",
    "title": "Are there any conditional access requirements for the application?",
    "recommendation": "",
    "id": "identity__access_control_9069",
    "context": "Modern cloud-based applications are often accessible over the internet and location-based networking restrictions don't make much sense, but it needs to be mapped and understood what kind of restrictions are required. Multi-factor Authentication (MFA) is a necessity for remote access, IP-based filtering can be used to enable ad-hoc debugging, but VPNs are preferred."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Identity & Access Control",
    "subCategory": "Authentication and authorization",
    "title": "Does the organization prioritize authentication via identity services for this workload vs. cryptographic keys?",
    "recommendation": "",
    "id": "identity__access_control_8570",
    "context": "Consideration should always be given to authenticating with identity services rather than cryptographic keys when available. Managing keys securely with application code is difficult and regularly leads to mistakes like accidentally publishing sensitive access keys to code repositories like GitHub. Identity systems (such as Azure Active Directory) offer secure and usable experience for access control with built-in sophisticated mechanisms for key rotation, monitoring for anomalies, and more."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "Does an access model exist and has it been implemented for Key Vaults to grant access to keys and secrets?",
    "recommendation": "",
    "id": "operational_procedures_3403",
    "context": "Permissions to keys and secrets have to be controlled with a [access model](https://docs.microsoft.com/azure/key-vault/general/secure-your-key-vault)."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "Who is responsible to manage the keys and secrets for the application?",
    "recommendation": "",
    "id": "operational_procedures_9157",
    "context": "Central SecOps team provides guidance on how keys and secrets are managed (governance), application DevOps team is responsible to manage the application related keys and secrets."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Operational Procedures",
    "subCategory": "Configuration & Secrets Management",
    "title": "What types of keys and secrets are used and how are those generated?",
    "recommendation": "",
    "id": "operational_procedures_6813",
    "context": "Different approaches can be used by the workload team. Decisions are often driven by security, compliance and specific data classification requirements. Understanding these requirements is important to determine which key types are best suitable (MMK - Microsoft-managed Keys, CMK - Customer-managed Keys or BYOK - Bring Your Own Key)."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Endpoints",
    "title": "Is there a clear distinction between endpoints exposed to public internet and internal ones?",
    "recommendation": "",
    "id": "networking__connectivity_1665",
    "context": "Web applications typically have one public entrypoint and don't expose subsequent APIs and database servers over the internet. When using gateway services like [Azure Front Door](https://docs.microsoft.com/azure/frontdoor/) it's possible to restrict access only to a set of Front Door IP addresses and lock down the infrastructure completely."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Endpoints",
    "title": "Are all external application endpoints secured?",
    "recommendation": "",
    "id": "networking__connectivity_6145",
    "context": "External application endpoints should be protected against common attack vectors, such as Denial of Service (DoS) attacks like Slowloris, to prevent potential application downtime due to malicious intent. Azure-native technologies such as Azure Firewall, Application Gateway/Azure Front Door WAF, and DDoS Protection Standard Plan can be used to achieve requisite protection (Azure DDoS Protection)."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Endpoints",
    "title": "Are public endpoints protected with firewall or WAF (Web Application Firewall)?",
    "recommendation": "",
    "id": "networking__connectivity_6733",
    "context": "[Azure Firewall](https://docs.microsoft.com/azure/firewall/features) is a managed, cloud-based network security service that protects Azure Virtual Network resources. [Web Application Firewall](https://docs.microsoft.com/azure/web-application-firewall/ag/ag-overview) (WAF) protects web applications against common attacks like cross-site scripting or SQL injection."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Connectivity",
    "title": "Are network restrictions used for non-public services?",
    "recommendation": "",
    "id": "networking__connectivity_5025",
    "context": "Azure provides networking solutions to restrict access to individual application services. Multiple levels (such as IP filtering or firewall rules) should be explored to prevent application services from being accessed by unauthorized actors."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Endpoints",
    "title": "Are application publishing methods restricted and protected?",
    "recommendation": "",
    "id": "networking__connectivity_4596",
    "context": "Application resources allowing multiple methods to publish app content (e.g FTP, Web Deploy) should have the unused endpoints disabled. For Azure Web Apps SCM is the recommended endpoint and it can be protected separately with network restrictions for sensitive scenarios. Developers shouldn't publish their code directly to app servers - automated and gated CI/CD process should manage this."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Connectivity",
    "title": "Is communication to Azure PaaS services secured using VNet Service Endpoints or Private Link?",
    "recommendation": "",
    "id": "networking__connectivity_6109",
    "context": "[Service Endpoints](https://docs.microsoft.com/azure/virtual-network/virtual-network-service-endpoints-overview) and [Private Link](https://docs.microsoft.com/azure/private-link/private-endpoint-overview) can be leveraged to restrict access to PaaS endpoints only from authorized virtual networks, effectively mitigating data intrusion risks and associated impact to application availability. Service Endpoints provide service level access to a PaaS service, while Private Link provides direct access to a specific PaaS resource to mitigate data exfiltration risks (e.g. malicious admin scenarios)."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Connectivity",
    "title": "If data exfiltration concerns exist for services where Private Link is not yet supported, is filtering via Azure Firewall or NVA (Network Virtual Appliance) being used?",
    "recommendation": "",
    "id": "networking__connectivity_2970",
    "context": "NVA solutions and Azure Firewall (for supported protocols) can be leveraged as a reverse proxy to restrict access to only authorized PaaS services for services where Private Link is not yet supported (Azure Firewall)."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Connectivity",
    "title": "Are Network Security Groups (NSGs) being used?",
    "recommendation": "",
    "id": "networking__connectivity_2840",
    "context": "If NSGs are being used to isolate and protect the application, the rule set should be reviewed to confirm that required services are not unintentionally blocked.",
    "children": [
      {
        "title": "Are NSG flow logs being collected?",
        "context": "NSG flow logs should be captured and analyzed to monitor performance and security. The NSG flow logs enables Traffic Analytics to gain insights into internal and external traffic flows of the application.",
        "recommendation": "",
        "id": "networking__connectivity_3405"
      }
    ]
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Data flow",
    "title": "Are there controls in place to detect and protect from data exfiltration?",
    "recommendation": "",
    "id": "networking__connectivity_3094",
    "context": "Data exfiltration occurs when an internal/external malicious actor performs and unauthorized data transfer. The solution should leverage a layered approach such as, hub/spoke for network communications with deep packet inspection to detect/protect from a data exfiltration attack. Azure Firewall, UDR (User-defined Routes), NSG (Network Security Groups), Key Protection, Data Encryption, PrivateLink, and Private Endpoints are layered defenses for a data exfiltration attack. Azure Sentinel and Azure Security Center can be used to detect data exfiltration attempts and alert incident responders."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Networking & Connectivity",
    "subCategory": "Data flow",
    "title": "Are there controls in place to control traffic between subnets, Azure components and tiers in the application?",
    "recommendation": "",
    "id": "networking__connectivity_8447",
    "context": "Data filtering between subnets and other Azure resources should be protected. Network Security Groups, PrivateLink, and Private Endpoints can be used for traffic filtering."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Encryption",
    "title": "Does the organization use industry standard encryption algorithms instead of creating their own?",
    "recommendation": "",
    "id": "encryption_8285",
    "context": "Organizations should rarely develop and maintain their own encryption algorithms. Secure standards already exist on the market and should be preferred. AES should be used as symmetric block cipher, AES-128, AES-192 and AES-256 are acceptable. Crypto APIs built into operating systems should be used where possible, instead of non-platform crypto libraries. For .NET make sure you follow the [.NET Cryptography Model](https://docs.microsoft.com/dotnet/standard/security/cryptography-model)."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Encryption",
    "title": "Is the client-server communication encrypted?",
    "recommendation": "",
    "id": "encryption_3568",
    "context": "Any network communication between client and server where man-in-the-middle attack can occur, needs to be encrypted. All website communication should use HTTPS, no matter the perceived sensitivity of transferred data (man-in-the-middle attacks can occur anywhere on the site, not just on login forms)."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Encryption",
    "title": "What TLS version is used across workloads?",
    "recommendation": "",
    "id": "encryption_1750",
    "context": "All Microsoft Azure services fully support TLS 1.2. It is recommended to migrate solutions to support **TLS 1.2** and use this version by default. TLS 1.3 is not available on Azure yet, but should be the preferred option once implemented on the platform."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Encryption",
    "title": "Are modern hashing functions used?",
    "recommendation": "",
    "id": "encryption_2236",
    "context": "Applications should use the **SHA-2** family of hash algorithms (SHA-256, SHA-384, SHA-512)."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Encryption",
    "title": "If using own data encryption keys (for encryption at rest), are they stored securely?",
    "recommendation": "",
    "id": "encryption_4598",
    "context": "Keys must be stored in a secure location with identity-based access control and audit policies. Data encryption keys are often encrypted with a key encryption key in Azure Key Vault to further limit access."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Encryption",
    "title": "How is data at rest protected?",
    "recommendation": "",
    "id": "encryption_704",
    "context": "This includes all information storage objects, containers, and types that exist statically on physical media, whether magnetic or optical disk.  All data should be classified and encrypted with an encryption standard.  How is the data classified and tagged as such so that it can be audited."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Security & Compliance",
    "subCategory": "Encryption",
    "title": "How is data in transit secured?",
    "recommendation": "",
    "id": "encryption_9315",
    "context": "When data is being transferred between components, locations, or programs, it’s in transit. Data in transit should be encrypted at all points to ensure data integrity. For example: web applications and APIs should use HTTPS/SSL for all communication with clients and also between each other (in micro-services architecture).",
    "children": [
      {
        "title": "Is there any portion of the application that does not secure data in transit?",
        "recommendation": "",
        "id": "encryption_5554",
        "context": "All data should be encrypted in transit using a common encryption standard. Determine if all components in the solution are using a consistent standard. There are times when encryption is not possible due to technical limitations, but the reason needs to be clear and valid."
      }
    ]
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "General",
    "title": "Has the organization adopted a formal DevOps approach to building and maintaining software to ensure security and feature enhancements can be deployed in rapid fashion?",
    "recommendation": "",
    "id": "operational_model__devops_7507",
    "context": "The DevOps approach increases the organization’s ability to rapidly address security concerns without waiting for a longer planning and testing cycle of traditional waterfall model. Key attributes are: automation, close integration of infra and dev teams, testability and reliability and repeatability of deployments.* [Adopt the DevOps approach](https://docs.microsoft.com/azure/architecture/framework/Security/applications-services#adopt-the-devops-approach)"
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "General",
    "title": "Does the organization leverage DevOps security guidance based on industry lessons-learned, and available automation tools (OWASP guidance, Microsoft toolkit for Secure DevOps etc.)?",
    "recommendation": "",
    "id": "operational_model__devops_9689",
    "context": "Organizations should leverage a control framework such as NIST, CIS or ASB [(Azure Security Benchmarks)](https://docs.microsoft.com/azure/security/benchmarks/) for securing applications on the cloud rather than starting from zero."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "Roles & Responsibilities",
    "title": "Do you have release gate approvals so that security teams can evaluate new features/code updates?",
    "recommendation": "",
    "id": "operational_model__devops_3654",
    "context": "Pull Requests and code reviews serve as the first line of approvals during development cycle. Before releasing new code to production (new features, bugfixes etc.), security review and approval should be required."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Operational Model & DevOps",
    "subCategory": "Roles & Responsibilities",
    "title": "Is the security team involved in the planning and design so that they can implement security controls, auditing, response processes into the solutions?",
    "recommendation": "",
    "id": "operational_model__devops_9812",
    "context": "There should be a process for onboarding service securely to Azure.  The onboarding process should include reviewing the configuration options to determine what logging/monitoring needs to be established, how to properly harden a resource before it goes into production.  For a list of common criteria for onboarding resoruces, see the [Service Enablement Framework](https://docs.microsoft.com/azure/cloud-adoption-framework/ready/enterprise-scale/security-governance-and-compliance#service-enablement-framework)"
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Deployments",
    "title": "Is credential scanning included as part of automated build process?",
    "recommendation": "",
    "id": "operational_model__devops_6801",
    "context": "Credentials should not be stored in source code or configuration files, because that increases the risk of exposure. Code analyzers (such as Roslyn analyzers for Visual Studio) can prevent from pushing credentials to source code repository and pipeline addons such as CredScan (part of Microsoft Security Code Analysis) help to catch credentials during the build process."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Deployments",
    "title": "How are credentials, certificates and other secrets managed in CI/CD pipelines?",
    "recommendation": "",
    "id": "operational_model__devops_7121",
    "context": "Secrets need to be managed in a secure manner inside of the CI/CD pipeline. The secrets needs to be stored either in a secure store inside the pipeline or externally in Azure Key Vault. When deploying application infrastructure (e.g. with Azure Resource Manager or Terraform), credentials and keys should be generated during the process, stored directly in Key Vault and referenced by deployed resources. Hardcoded credentials should be avoided."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Deployments",
    "title": "Is code scan included in continuos integration (CI) process and are dependencies and framework components covered by this process?",
    "recommendation": "",
    "id": "operational_model__devops_4898",
    "context": "As part of the continuous integration process it is crucial that every release includes a scan of all components in use. Vulnerable dependencies should be flagged and investigated. This can done in combination with other code scanning tasks (e.g. code churn, test results/coverage)."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Testing & Validation",
    "title": "Are you using Azure Security Center (ASC) to scan containers for vulnerabilities? Or any third-party solution?",
    "recommendation": "",
    "id": "operational_model__devops_792",
    "context": "Azure Security Center is the Azure-native solution for securing containers. Security Center can protect virtual machines that are running Docker, Azure Kubernetes Service clusters, Azure Container Registry registries. ASC is able to scan container images and identify security issues, or provide real-time threat detection for containerized environments. [Container Security in Security Center](https://docs.microsoft.com/azure/security-center/container-security)"
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Application Deployments",
    "title": "Are branch policies used in source control management? How are they configured?",
    "recommendation": "",
    "id": "operational_model__devops_5927",
    "context": "Branch policies provide additional level of control over the code which is commited to the product. It is a common practice to not allow pushing against the main branch and require pull-request (PR) with code review before merging the changes by at least one reviewer, other than the change author. Different branches can have different purposes and access levels, for example: feature branches are created by developers and are open to push, integration branch requires PR and code-review and production branch requires additional approval from a senior developer before merging."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Build Environments",
    "title": "Are self-hosted build agents used in the Azure DevOps CI/CD pipelines?",
    "recommendation": "",
    "id": "deployment_testing_4387",
    "context": "When the organization uses their own build agents it adds management complexity and can become an attack vector. Build machine credentials must be stored securely and file system needs to be cleaned of any temporary build artifacts regularly. Network isolation can be achieved by only allowing outgoing traffic from the build agent, because it's using pull model of communication with Azure DevOps."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "Deployment & Testing",
    "subCategory": "Testing & Validation",
    "title": "Does the organization perform penetration testing or have a third-party entity perform penetration testing to validate the current security defenses put in place?",
    "recommendation": "",
    "id": "deployment_testing_4013",
    "context": "Real world validation of security defenses is critical to validate a defense strategy and implementation. Penetration tests or red team programs can be used to simulate either one time, or persistent threats against an organization to validate defenses that have been put in place to protect organizational resources."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "General",
    "subCategory": "Unassigned",
    "title": "Is the organization using a Landing Zone concept and how was it implemented?",
    "recommendation": "",
    "id": "governance_2724",
    "context": "The purpose of the “Landing Zone” is to ensure that when a workload lands on Azure, the required “plumbing” is already in place, providing greater agility and compliance with enterprise security and governance requirements. This is crucial, that a Landing Zone will be handed over to the workload owner with the security guardrails deployed."
  },
  {
    "type": "Questions",
    "pillars": [
      "security"
    ],
    "lens": "application",
    "category": "General",
    "subCategory": "Unassigned",
    "title": "Are Azure policies used to enforce security and compliance configuration?",
    "recommendation": "",
    "id": "governance_1113",
    "context": "Azure Policy should be used to enforce and report a compliant configuration of Azure services. Azure policies can be use on multiple levels. It is recommended to apply organizational wide security controls on Azure platform level. These policies build the guardrails of a landing zone."
  },
  {
    "type": "Design Principles",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "General",
    "subCategory": "Unassigned",
    "title": "Optimize build and release processes",
    "context": "From provisioning with Infrastructure as Code, to build and releases with CI/CD pipelines, to automated testing, embrace software engineering discipline across your entire environment. This approach ensures the creation and management of environments throughout the software development lifecycle is consistent and enables early detection of issues.",
    "id": "dp_opex_1"
  },
  {
    "type": "Design Principles",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "General",
    "subCategory": "Unassigned",
    "title": "Monitor system and operational health",
    "context": "Identify and monitor metrics for build and release processes, infrastructure health, and application health. Telemetry is critical to understanding the health of a workload and whether the service is meeting the business goals.",
    "id": "dp_opex_2"
  },
  {
    "type": "Design Principles",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "General",
    "subCategory": "Unassigned",
    "title": "Rehearse recovery and practice failure",
    "context": "Run DR drills on regular cadence and use chaos engineering practices to identify and remediate weak points in application reliability. Regular rehearsal of failure will validate the effectiveness of recovery processes and ensure teams are familiar with their responsibilities.",
    "id": "dp_opex_3"
  },
  {
    "type": "Design Principles",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "General",
    "subCategory": "Unassigned",
    "title": "Modularize your environment",
    "context": "Systematically componentize your environment and workloads to enable frequent and manageable change that can be progressively rolled-out and safely rolled-back.",
    "id": "dp_opex_4"
  },
  {
    "type": "Design Principles",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "General",
    "subCategory": "Unassigned",
    "title": "Use policy-driven governance",
    "context": "Use Azure Policy to provide guardrails and ensure continued compliance of application environment. This approach to centralized governance enables an organization to provide application teams with sufficient autonomy to accelerate development efforts, while ensuring the enterprise estate remains compliant with organizational standards.",
    "id": "dp_opex_5"
  },
  {
    "type": "Design Principles",
    "pillars": [
      "operationalexcellence"
    ],
    "lens": "application",
    "category": "General",
    "subCategory": "Unassigned",
    "title": "Embrace operational improvement",
    "context": "Continuously evaluate and refine operational procedures and tasks, while striving to reduce complexity and ambiguity. This approach enables an organization to evolve processes over time, optimizing inefficiencies and learning from failures.",
    "id": "dp_opex_6"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Virtual Machines",
    "title": "Microsoft provides a 1) 95% SLA for single instance virtual machines using Standard HDD storage for all OS and Data disks, 2) 99.5% SLA for single instance virtual machines using Standard SSD storage for all OS and Data disks, 3) 99.9% SLA for single instance virtual machines using Premium storage for all OS and Data disks, 4) 99.95% SLA for all virtual machines that have two or more instances in the same Availability Set or Dedicated Host Group, and a 5) 99.99% SLA for all virtual machines that have two or more instances deployed across two or more Availability Zones in the same region.",
    "context": "[Virtual Machine Service Level Agreements](https://azure.microsoft.com/support/legal/sla/virtual-machines/v1_9/)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Virtual Machines",
    "title": "For all virtual machines requiring resiliency, it is highly recommended that:",
    "children": [
      {
        "title": "Managed Disks should be used for all virtual machine OS and Data disks to ensure resilience across underlying storage stamps within a datacenter.",
        "context": "[Managed Disk Benefits](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/managed-disks-overview#benefits-of-managed-disks)"
      },
      {
        "title": "Singleton workloads should use Premium Managed Disks to enhance resiliency and obtain a 99.9% SLA as well as dedicated performance characteristics."
      },
      {
        "title": "Non-Singleton workloads should consider two or more replica instances with Managed disks (Standard or Premium) that are deployed within an Availability Set to obtain a 99.95% SLA or across Availability Zones to obtain a 99.95% SLA."
      },
      {
        "title": "Where appropriate virtual machines should be deployed across Availability Zones to maximize resilience within a region.",
        "context": "[Datacenter Fault Tolerance](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/manage-availability#use-availability-zones-to-protect-from-datacenter-level-failures)"
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Virtual Machines",
    "title": "Azure Metadata Service Scheduled Events should be used to proactively respond to maintenance events (i.e. reboots) and limit disruption to virtual machines.",
    "context": "[Azure Metadata Service Scheduled Events](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/scheduled-events)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Virtual Machines",
    "title": "Azure Backup should be used to back-up virtual machines within a Recovery Services Vault, to protect against accidental data loss.",
    "context": "[Azure Backup](https://docs.microsoft.com/en-us/azure/backup/backup-azure-vms-introduction)",
    "children": [
      {
        "title": "Enable Soft Delete for the Recovery Services vault to protect against accidental or malicious deletion of backup data, ensuring the ability to recover.",
        "context": "[Azure Backup Soft Delete](https://docs.microsoft.com/en-us/azure/backup/backup-azure-security-feature-cloud)"
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Virtual Machines",
    "title": "Enable diagnostic logging for all virtual machines to ensure health metrics, boot diagnostics and infrastructure logs are routed to Log Analytics or an alternative log aggregation technology.",
    "context": "[Diagnostic Logs](https://docs.microsoft.com/en-us/azure/azure-monitor/platform/platform-logs-overview)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Virtual Machines",
    "title": "Establish virtual machine Resource Health alerts to notify key stakeholders when resource health events occur.",
    "context": "An appropriate threshold for resource unavailability must be set to minimize signal to noise ratios so that transient faults do not generate an alert. For example, configuring a virtual machine alert with an unavailability threshold of 1 minute before an alert is triggered.[Resource Health Alerts](https://docs.microsoft.com/en-gb/azure/service-health/resource-health-alert-arm-template-guide)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Virtual Machines",
    "title": "To ensure application scalability while navigating within disk sizing thresholds, it is highly recommended that applications be installed on data disks rather than the OS disk."
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Virtual Machines",
    "title": "To identify resiliency risks to existing compute resources and support continuous compliance for new resources within a customer tenant, it is recommended that Azure Policy and Azure Resource Graph be used to Audit the use of non-resilient deployment configurations."
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Virtual Machines",
    "title": "Query to **identify standalone single instance VMs that are not protected by a minimum SLA of at least 99.5%**. It will return all VM instances that are not deployed within an Availability Set or across Availability Zones and are not using either Standard SSD or Premium SSD for both OS and Data disks.",
    "children": [
      {
        "title": "This query can easily be altered to identify all single instance VMs including those using Premium Storage which are protected by a minimum SLA of at least 99.5%; simply remove the trailing where condition.",
        "code": "Resources\n| where\n    type =~ 'Microsoft.Compute/virtualMachines'\n        and isnull(properties.availabilitySet.id)\n    or type =~ 'Microsoft.Compute/virtualMachineScaleSets'\n        and sku.capacity <= 1\n        or properties.platformFaultDomainCount <= 1\n| where \n    tags != '{\"Skip\":\"\"}'\n| where \n    isnull(zones)\n| where\n\tproperties.storageProfile.osDisk.managedDisk.storageAccountType !in ('Premium_LRS'\n\tor properties.storageProfile.dataDisks.managedDisk.storageAccountType != 'Premium_LRS'\n\t    and array_length(properties.storageProfile.dataDisks) != 0\n"
      }
    ]
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Virtual Machines",
    "title": "The following query expands on the identification of standalone instances by **identifying any Availability Sets containing single instance VMs**, which are exposed to the same risks as standalone single instances outside of an Availability Set.",
    "code": "Resources\n| where \n    type =~ 'Microsoft.Compute/availabilitySets'\n| where \n    tags != '{\"Skip\":\"\"}'\n| where \n\tarray_length(properties.virtualMachines) <= 1\n| where\n\tproperties.platformFaultDomainCount <= 1\n"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Virtual Machines",
    "title": "Azure policy definition to **audit standalone single instance VMs that are not protected by a SLA**. It will flag an audit event for all Virtual Machine instances that are not deployed within an Availability Set or across Availability Zones and are not using Premium Storage for both OS and Data disks. It also encompasses both Virtual Machine and Virtual Machine Scale Set resources.",
    "context": "[Audit VM/VMSS Standalone Instances](../src/compute/policydefinition_Audit-VMStandaloneInstances.json)"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Virtual Machines",
    "title": "Azure policy definition to **audit Availability Sets containing single instance VMs that are not protected by a SLA**. It will flag an audit event for all Availability Sets that does not contain multiple instances.",
    "context": "[Audit Availability Sets With Single Instances](../src/compute/policydefinition_Audit-AvailabilitySetSingleInstances.json)"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure Kubernetes Service (AKS)",
    "title": "For customers subscribing to the Azure Kubernetes Service (AKS) Uptime SLA, Microsoft guarantees 1) 99.95% availability of the Kubernetes API server endpoint for AKS Clusters that use Azure Availability Zones, and 2) 99.9% availability for AKS Clusters that not use Azure Availability Zones. For customers that do not wish to subscribe to the AKS uptime SLA, Microsoft provides a service level objective (SLO) of 99.5%."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure Kubernetes Service (AKS)",
    "title": "The SLA for agent (worker) nodes within an AKS cluster is covered by the standard [Virtual Machine SLA](#virtual-machines) which is dependent on the chosen deployment configuration and whether an Availability Set or Availability Zones are used.",
    "context": "[AKS Service Level Agreements](https://azure.microsoft.com/support/legal/sla/kubernetes-service/v1_1/)[AKS Uptime SLA Offering](https://docs.microsoft.com/en-us/azure/aks/uptime-sla)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure Kubernetes Service (AKS)",
    "title": "For all AKS clusters requiring resiliency, it is highly recommended that:",
    "children": [
      {
        "title": "Use [Availability Zones](https://docs.microsoft.com/azure/aks/availability-zones) to maximize resilience within a region by distributing AKS agent nodes across physically separate data centers."
      },
      {
        "title": "Where co-locality requirements exist, an Availability Set deployment can be used to minimize inter-node latency."
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure Kubernetes Service (AKS)",
    "title": "Virtual Machine Scale Set deployment configurations should be used to unlock cluster autoscaling and the use of multiple node pools.",
    "children": [
      {
        "title": "Enable cluster [autoscaling](https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler) to adjust the number of agent nodes in response to resource constraints."
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure Kubernetes Service (AKS)",
    "title": "Use [Managed Identities](https://docs.microsoft.com/azure/aks/use-managed-identity) to avoid having to manage and rotate service principles."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure Kubernetes Service (AKS)",
    "title": "Modifying resources in the node resource group (ie - 'MC_') is not recommended and should only be done with assistance from support."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure Kubernetes Service (AKS)",
    "title": "Adopt a [multi-region strategy](https://docs.microsoft.com/en-gb/azure/aks/operator-best-practices-multi-region#plan-for-multiregion-deployment) by deploying AKS clusters deployed across different Azure regions to maximize availability and provide business continuity.",
    "children": [
      {
        "title": "Internet facing workloads should leverage Azure Front Door, [Azure Traffic Manager](https://docs.microsoft.com/en-gb/azure/aks/operator-best-practices-multi-region#use-azure-traffic-manager-to-route-traffic), or a third-party CDN to route traffic globally across AKS clusters."
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure Kubernetes Service (AKS)",
    "title": "Store container images within Azure Container Registry and enable [geo-replication](https://docs.microsoft.com/azure/aks/operator-best-practices-multi-region#enable-geo-replication-for-container-images) to replicate container images across leveraged AKS regions. "
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure Kubernetes Service (AKS)",
    "title": "Query to identify AKS clusters that are not deployed across **Availability Zones**:",
    "code": "Resources\n| where\n    type =~ 'Microsoft.ContainerService/managedClusters'\n\tand isnull(zones)\n"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure Kubernetes Service (AKS)",
    "title": "Query to identify AKS clusters that are deployed within a AvailabilitySet:",
    "code": "Resources\n| where\n    type =~ 'Microsoft.ContainerService/managedClusters'\n\tand properties.agentPoolProfiles[0].type != 'VirtualMachineScaleSets'\n| project name, location, resourceGroup, subscriptionId, properties.agentPoolProfiles[0].type\n"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure Kubernetes Service (AKS)",
    "title": "Query to identify AKS clusters that are not deployed using a **Managed Identity**:",
    "code": "Resources\n| where\n    type =~ 'Microsoft.ContainerService/managedClusters'\n\tand isnull(identity)\n"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure App Service",
    "title": "Microsoft guarantees that Apps will be available 99.95% of the time. However, no SLA is provided for Apps using either the Free or Shared tiers.",
    "context": "[SLA for App Service](https://azure.microsoft.com/en-us/support/legal/sla/app-service/v1_4/)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure App Service",
    "title": "Azure App Service provides a number of configuration options that are not enabled by default. For all App Services requiring resiliency, it is highly recommended that:",
    "children": [
      {
        "title": "Use Basic or higher plans with 2 or more worker instances for high availability."
      },
      {
        "title": "Evaluate the use of [TCP and SNAT ports](https://docs.microsoft.com/en-us/azure/app-service/troubleshoot-intermittent-outbound-connection-errors#cause) to avoid outbound connection errors",
        "context": "TCP connections are used for all outbound connections whereas SNAT ports are used when making outbound connections to public IP addresses.SNAT port exhaustion is a common failure scenario that can be predicted by load testing while monitoring ports using Azure Diagnostics. If a load test results in SNAT errors, it is necessary to either scale across more/larger workers, or implement coding practices to help preserve and re-use SNAT ports, such as connection pooling and the lazy loading of resources.It is recommended not to exceed 100 simultaneous outbound connections to a public IP Address per worker, and to avoid communicating with downstream services via public IP addresses when a private address (Private Endpoint) or Service Endpoint through vNet Integration could be used.TCP port exhaustion happens when the sum of connection from a given worker exceeds the capacity. The number of available TCP ports depend on the size of the worker. The following table lists the current limits:\n\n    > |  |Small (B1, S1, P1, I1)|Medium (B2, S2, P2, I2)|Large (B3, S3, P3, I3)|\n    > |---------|---------|---------|---------|\n    > |TCP ports|1920|3968|8064|\n\n    > Applications with lots of longstanding connections require ports to be left open for long periods of time, which can lead to TCP Connection exhaustion. TCP Connection limits are fixed based on instance size, so it is necessary to scale up to a larger worker size to increase the allotment of TCP connections, or implement code level mitigations to govern connection usage. Similar to SNAT port exhaustion, Azure Diagnostics can be used to identify if a problem exists with TCP port limits."
      },
      {
        "title": "Enable [AutoHeal](https://azure.github.io/AppService/2018/09/10/Announcing-the-New-Auto-Healing-Experience-in-App-Service-Diagnostics.html) to automatically recycle unhealthy workers.",
        "context": "This feature is currently only available to Windows Plans."
      },
      {
        "title": "Enable [Health Check](https://aka.ms/appservicehealthcheck) to identify non-responsive workers.",
        "context": "Any health check is better than none at all, however, the logic behind endpoint tests should assess all critical downstream dependencies to ensure overall health. It is also recommended practice to track application health and cache status in real time as this removes unnecessary delays before  action can be taken."
      },
      {
        "title": "Enable [AutoScale](https://docs.microsoft.com/en-us/azure/azure-monitor/platform/autoscale-get-started?toc=/azure/app-service/toc.json) to ensure adequate resources are available to service requests.",
        "context": "The default limit of App Service workers is 30.  If the App Service routinely uses 15 or more instances, consider opening a support ticket to increase the maximum number of workers to 2x the instance count required to serve normal peak load."
      },
      {
        "title": "Enable [Local Cache](https://docs.microsoft.com/en-us/azure/app-service/overview-local-cache) to reduce dependencies on cluster file servers.",
        "context": "Enabling local cache is not always appropriate because it can lead to slower worker startup times. However, when coupled with Deployment Slots, it can improve resiliency by removing dependencies on file servers and also reduces storage-related recycle events. However, Local cache should not be used with a single worker instance or when shared storage is required."
      },
      {
        "title": "Enable [Diagnostic Logging](https://docs.microsoft.com/en-us/Azure/app-service/troubleshoot-diagnostic-logs) to provide insight into application behavior.",
        "context": "Diagnostic logging provides the ability to ingest rich application and platform level logs into either Log Analytics, Azure Storage, or a third party tool via Event Hub."
      },
      {
        "title": "Enable [Application Insights Alerts](https://docs.microsoft.com/en-us/Azure/azure-monitor/app/azure-web-apps) to be made aware of fault conditions.",
        "context": "Application performance monitoring with Application Insights provides deep insights into application performance. For Windows Plans a 'codeless deployment' approach is possible to quickly get insights without changing any code."
      },
      {
        "title": "Review [Azure App Service diagnostics](https://docs.microsoft.com/en-us/azure/app-service/overview-diagnostics) to ensure common problems are addressed.",
        "context": "It is a good practice to regularly review service-related diagnostics and recommendations and take action as appropriate."
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure App Service",
    "title": "For App Service Environments, ensure ASE is deployed within in [highly available configuration](https://docs.microsoft.com/en-us/azure/architecture/reference-architectures/enterprise-integration/ase-high-availability-deployment) across Availability Zones.",
    "context": "Configuring ASE to use Availability Zones by deploying ASE across specific zones ensures applications can continue to operate even in the event of a data center level failure. This provides excellent redundancy without requiring multiple deployments in different Azure regions."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure App Service",
    "title": "For App Service Environments, ensure the [ASE Network](https://docs.microsoft.com/en-us/azure/app-service/environment/network-info) is configured correctly.",
    "context": "One common ASE pitfall occurs when ASE is deployed into a subnet with an IP Address space that is too small to support future expansion. In such cases, ASE can be left unable to scale without redeploying the entire environment into a larger subnet. It is highly recommended that adequate IP addresses be used to support either the maximum number of workers or the largest number considered workloads will need. A single ASE cluster can scale to 201 instance, which would require a /24 subnet."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure App Service",
    "title": "For App Service Environments, consider configuring [Upgrade Preference](https://docs.microsoft.com/en-us/azure/app-service/environment/using-an-ase#upgrade-preference) if multiple environments are used.",
    "context": "If lower environments are used for staging or testing, consideration should be given to configuring these environments to receive updates sooner than the production environment. This will help to identify any conflicts or problems with an update and provides a window to mitigate issues before they reach the production environment.If multiple load balanced (zonal) production deployments are used, upgrade preference can also be used to protect the broader environment against issues from platform upgrades."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure App Service",
    "title": "For App Service Environments, plan for scaling out the ASE cluster",
    "context": "Scaling ASE instances vertically or horizontally currently takes 30-60 minutes as new private instances need to be provisioned. It is highly recommended that effort be invested up-front to plan for scaling during spikes in load or transient failure scenarios."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure App Service",
    "title": "When deploying application code or configuration, it is highly recommended that:",
    "children": [
      {
        "title": "Use [Deployment Slots](https://docs.microsoft.com/en-us/azure/app-service/deploy-staging-slots) for resilient code deployments.",
        "context": "Deployment Slots allow for code to be deployed to instances that are warmed-up before serving production traffic.[Azure Friday](https://www.youtube.com/watch?v=MP8fXgxq6xo)[blog post](https://ruslany.net/2019/06/azure-app-service-deployment-slots-tips-and-tricks/)"
      },
      {
        "title": "Avoid Unnecessary Worker restarts",
        "context": "There are a number of events that can lead App Service workers to restart, such as content deployment, App Settings changes, and VNet integration configuration changes. It is best practice to make changes in a deployment slot other than the slot currently configured to accept production traffic. After workers are recycled and warmed up, a \"swap\" can be performed without unnecessary down time."
      },
      {
        "title": "Use [\"Run From Package\"](https://docs.microsoft.com/en-us/azure/app-service/deploy-run-package) to avoid deployment conflicts",
        "context": "Run from Package provides several advantages:Eliminates file lock conflicts between deployment and runtime.Ensures only full-deployed apps are running at any time.May reduce cold-start times, particularly for JavaScript functions with large npm package trees."
      }
    ]
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure App Service",
    "title": "Query to identify App Service Plans with **only 1 instance**:",
    "code": "Resources\n| where type == \"microsoft.web/serverfarms\" and properties.computeMode == 'Dedicated'\n| where sku.capacity == 1\n"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Azure App Service",
    "title": "[The Ultimate Guide to Running Healthy Apps in the Cloud](https://azure.github.io/AppService/2020/05/15/Robust-Apps-for-the-cloud.html)"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "Azure Service Fabric does not provide its own SLA. The availability of Service Fabric clusters is based on the underlying Virtual Machine and Storage resources used."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "Virtual Machine Scale Sets also do not have an SLA, since the SLA for Virtual Machines applies here. If the Virtual Machine Scale Set includes Virtual Machines in at least 2 Fault Domains, the availability of the underlying Virtual Machines SLA for two or more instances applies. If the scale set contains a single Virtual Machine, the availability for a Single Instance Virtual Machine applies.",
    "context": "[Service Fabric](https://azure.microsoft.com/en-us/support/legal/sla/service-fabric/v1_0/)[Virtual Machine Scale Set](https://azure.microsoft.com/en-us/support/legal/sla/virtual-machine-scale-sets/v1_1/)"
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "Review the [Service Fabric production readiness checklist](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-production-readiness-checklist)"
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "Use durability level Silver (5 VMs) or higher for production scenarios. ",
    "context": "This will ensure the Azure infrastructure communicates with the Service Fabric controller on scheduling reboots, etc."
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "For critical workloads, consider using Availability Zones for your Service Fabric clusters. ",
    "context": "This means deploying a primary NodeType (and by extension a VM ScaleSet) to each AZ. This will ensure that the Service Fabric system services are spread across zones."
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "To expose services on the Service Fabric cluster, use a reverse proxy such as the Service Fabric reverse proxy or Traefik. When exposing APIs hosted on the cluster, consider using Azure API Management.",
    "context": "API Management can [integrate](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-api-management-overview) with Service Fabric directly."
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "For production scenarios, use the Standard tier load balancer. The Basic SKU is free, but does not have an SLA."
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "Keep the different node types and gateway services on different subnets."
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "Apply Network Security Groups (NSG) to restrict traffic flow between subnets/node types. Ensure that the [correct ports](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-best-practices-networking#cluster-networking) are opened for managing the cluster. ",
    "context": "For example, you may have an API Management instance (one subnet), a frontend subnet (exposing a website directly) and a backend subnet (accessible only to frontend), each implemented on a different VM Scale Set."
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "When using secrets (connection strings, passwords) in SF services, either retrieve them directly from Key Vault at runtime or use the [Service Fabric Secrets Store](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-application-secret-store)"
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "When using the Service Fabric Secret Store to distribute secrets, use a separate data encipherment certificate to encrypt the values. ",
    "context": "This certificate is deployed to the VM scaleset nodes to decrypt the secret values. When using this approach, ensure that secrets are inserted and encrypted at release time. Using this approach means that changing the secrets requires a deployment. Make sure your key-rotation process is fully automated to do this without downtime."
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "Do not use self-signed certificates for production scenarios. Either provision a certificate through your PKI or use a public certificate authority."
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "Deploy certificates by adding them to Azure Keyvault and referencing the URI in your deployment."
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "Have a process in place for monitoring the expiration date of certificates.",
    "context": "For example, Key Vault offers a feature that sends an email when x% of the certificate's lifespan has elapsed."
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "Enable Azure Active Directory integration for your cluster to ensure users can access Service Fabric Explorer using their AAD credentials. Do not distribute the cluster certificate among users to access Explorer. "
  },
  {
    "type": "Design Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Compute",
    "subCategory": "Service Fabric",
    "title": "Exclude the Service Fabric processes from Windows Defender to improve performance",
    "context": "By default, Windows Defender antivirus is installed on Windows Server 2016 and 2019. To reduce any performance impact and resource consumption overhead incurred by Windows Defender, and if your security policies allow you to exclude processes and paths for open-source software, you can [exclude](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-best-practices-security#windows-defender) the Service Fabric executables from Defender scans."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Azure SQL Database is a fully managed platform as a service (PaaS) database engine that handles most of the database management functions. Azure SQL Database is always running on the latest stable version of the SQL Server database engine and patched OS with 99.99% availability. PaaS capabilities that are built into Azure SQL Database enable you to focus on the domain-specific database administration and optimization activities that are critical for your business. "
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Azure SQL Database is having built-in regional high availability and turnkey geo-replication to any Azure region. It includes intelligence to support self-driving features such as performance tuning, threat monitoring, and vulnerability assessments and provides fully automated patching and updating of the code base."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Azure SQL Database Business Critical or Premium tiers configured as Zone Redundant Deployments have an availability guarantee of at least 99.995%."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Azure SQL Database Business Critical or Premium tiers not configured for Zone Redundant Deployments, General Purpose, Standard, or Basic tiers, or Hyperscale tier with two or more replicas have an availability guarantee of at least 99.99%."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Azure SQL Database Hyperscale tier with one replica has an availability guarantee of at least 99.95% and 99.9% for zero replicas."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Azure SQL Database Business Critical tier configured with geo-replication has a guarantee of Recovery point objective (RPO) of 5 sec for 100% of deployed hours."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Azure SQL Database Business Critical tier configured with geo-replication has a guarantee of Recovery time objective (RTO) of 30 sec for 100% of deployed hours."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Use point-in-time restore to recover from human error. Point-in-time restore returns your database to an earlier point in time to recover data from changes done inadvertently. For more information, read the PITR documentation for https://docs.microsoft.com/en-us/azure/azure-sql/database/recovery-using-backups#point-in-time-restore "
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Use geo-restore to recover from a service outage. You can restore a database on any SQL Database server or an instance database on any managed instance in any Azure region from the most recent geo-replicated backups. Geo-restore uses a geo-replicated backup as its source. You can request geo-restore even if the database or datacenter is inaccessible due to an outage. Geo-restore restores a database from a geo-redundant backup. For more information, see [Recover an Azure SQL database using automated database backups](https://docs.microsoft.com/azure/sql-database/sql-database-recovery-using-backups)"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Use sharding Sharding is a technique of distributing data and processing across many identically structured databases, provides an alternative to traditional scale-up approaches both in terms of cost and elasticity. Consider using sharding to partition the database horizontally. Sharding can provide fault isolation. For more information, see [Scaling out with Azure SQL Database.](https://docs.microsoft.com/azure/sql-database/sql-database-elastic-scale-introduction)"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Define an application performance SLA and monitor it with alerts. Detecting quickly when your application performance inadvertently degrades below an acceptable level is important to maintain high resiliency. Use the monitoring solution defined above to set alerts on key query performance metrics to you can take action when the performance breaks the SLA. [Monitor Your Database](https://docs.microsoft.com/en-us/azure/azure-sql/database/monitor-tune-overview)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Configure HA/DR that best feed your needs from following options: Azure Sql DB  offers the following capabilities for recovering from an outage, It is advised to implement one or combination of one or more depending on Business RTO/RPO requirements : ",
    "children": [
      {
        "title": "Use Active Geo-Replication:  Use Active Geo-Replication to create a readable secondary in a different region. If your primary database fails, perform a manual failover to the secondary database. Until you fail over, the secondary database remains read-only. [Active geo-replication](https://docs.microsoft.com/en-us/azure/azure-sql/database/active-geo-replication-overview) enables you to create readable replicas and manually failover to any replica in case of a datacenter outage or application upgrade. Up to 4 secondaries are supported in the same or different regions, and the secondaries can also be used for read-only access queries. The failover must be initiated manually by the application or the user. After failover, the new primary has a different connection end point. "
      },
      {
        "title": "Use Auto Failover Groups: A failover group can include one or multiple databases, typically used by the same application. Additionally, you can use the readable secondary databases to offload read-only query workloads. Because auto-failover groups involve multiple databases, these databases must be configured on the primary server. Auto-failover groups support replication of all databases in the group to only one secondary server or instance in a different region. Learn more about [AutoFailover Groups](https://docs.microsoft.com/en-us/azure/azure-sql/database/auto-failover-group-overview?tabs=azure-powershell)  and  [DR design](https://docs.microsoft.com/en-us/azure/azure-sql/database/designing-cloud-solutions-for-disaster-recovery).\t"
      },
      {
        "title": "Use Zone-Redundant database: By default, the cluster of nodes for the premium availability model is created in the same datacenter. With the introduction of Azure Availability Zones, SQL Database can place different replicas of the Business Critical database to different availability zones in the same region. To eliminate a single point of failure, the control ring is also duplicated across multiple zones as three gateway rings (GW). The routing to a specific gateway ring is controlled by [Azure Traffic Manager](https://docs.microsoft.com/en-us/azure/traffic-manager/traffic-manager-overview) (ATM). Because the zone redundant configuration in the Premium or Business Critical service tiers does not create additional database redundancy, you can enable it at no extra cost. Learn More on Zone-redundant databases [here](https://docs.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla) "
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Monitor your Azure SQL DB in near-real time to detect reliability incidents. Use one of the available solutions to monitor SQL DB to detect potential reliability incidents early and make your databases more reliable. Choosing a near real-time monitoring solution is key to quickly react to incidents. Learn more details about Azure SQL Analytics [Here](https://docs.microsoft.com/en-us/azure/azure-monitor/insights/azure-sql#analyze-data-and-create-alerts)  "
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Backup your keys: If you are not [using encryption keys in Azure key vault to protect your data](https://docs.microsoft.com/en-us/azure/sql-database/sql-database-always-encrypted-azure-key-vault) , backup your keys!"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Database",
    "title": "Implement Retry Logic: Although Azure SQL Database is resilient on the transitive infrastructure failures, these failures might affect your connectivity. When a transient error occurs while working with SQL Database, make sure your code must be able to retry the call. Follow the link for detailed instruction on how to [Implement retry logic](https://docs.microsoft.com/en-us/azure/azure-sql/database/troubleshoot-common-connectivity-issues). "
  },
  {
    "type": "Design Considerations ",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Managed Instance",
    "title": "Use point-in-time restore to recover from human error. Point-in-time restore returns your database to an earlier point in time to recover data from changes done inadvertently. For more information, read the [PITR documentation for managed instance](https://docs.microsoft.com/en-us/azure/azure-sql/database/recovery-using-backups#point-in-time-restore)"
  },
  {
    "type": "Design Considerations ",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Managed Instance",
    "title": "Use geo-restore to recover from a service outage. Geo-restore restores a database from a geo-redundant backup into a managed instance in a different region. For more information, see [Recover a database using Geo-restore documentation](https://docs.microsoft.com/en-us/azure/azure-sql/database/auto-failover-group-overview)"
  },
  {
    "type": "Design Considerations ",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Managed Instance",
    "title": "Define an application performance SLA and monitor it with alerts. Detecting quickly when your application performance inadvertently degrades below an acceptable level is important to maintain high resiliency. Use the monitoring solution defined above to set alerts on key query performance metrics to you can take action when the performance breaks the SLA."
  },
  {
    "type": "Design Considerations ",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Managed Instance",
    "title": "Consider the time required for certain operations. Make sure you separate time to thoroughly test the amount of time required to scale up and down (change the size) your existing managed instance, and to create a new managed instance. This will ensure that you understand completely how these time consuming operations will affect your RTO and RPO."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Managed Instance",
    "title": "Use Business Critical tier. This tier provides higher resiliency to failures and faster failover times due to the underlying HA architecture, among other benefits. For more information, see [SQL Managed Instance High availability](https://docs.microsoft.com/en-us/azure/azure-sql/database/high-availability-sla)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Managed Instance",
    "title": "Configure a secondary instance and an Auto-failover group to enable failover to another region. If an outage impacts one or more of the databases in the managed instance, you can manually or automatically failover all the databases inside the instance to a secondary region. For more information, read the [Auto-failover groups documentation for managed instance](https://docs.microsoft.com/en-us/azure/azure-sql/database/auto-failover-group-overview)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Managed Instance",
    "title": "Monitor your SQL MI instance in near-real time to detect reliability incidents. Use one of the available solutions to monitor your SQL MI to detect potential reliability incidents early and make your databases more reliable. Choosing a near real-time monitoring solution is key to quickly react to incidents. For more information, read the [Azure SQL Managed Instance monitoring options](http://aka.ms/mi-monitoring)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure SQL Managed Instance",
    "title": "Implement Retry Logic: Although Azure SQL MI is resilient on the transitive infrastructure failures, these failures might affect your connectivity. When a transient error occurs while working with SQL MI, make sure your code must be able to retry the call. Follow the link for detailed instruction on how to [Implement retry logic](https://docs.microsoft.com/en-us/azure/azure-sql/database/troubleshoot-common-connectivity-issues). "
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "99.99% SLAs for throughput, consistency, availability and latency for Database Accounts scoped to a single Azure region configured with any of the five Consistency Levels or Database Accounts spanning to multiple Azure regions, configured with any of the four relaxed Consistency Levels. "
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "99.999% SLA for read availability for Database Accounts spanning two or more Azure region."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "99.999% SLA for both read and write availability with the configuration of multiple Azure regions as writable endpoints.",
    "context": "[Cosmos DB Service Level Agreements](https://azure.microsoft.com/en-us/support/legal/sla/cosmos-db/v1_3/)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "It is strongly recommended that you configure the Azure Cosmos accounts used for production workloads to enable [automatic failover](https://docs.microsoft.com/en-us/azure/cosmos-db/high-availability#multi-region-accounts-with-a-single-write-region-write-region-outage). "
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "Session is default consistency level, and it is the most widely used [consistency level](https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels). It is the recommended consistency level to start with as it receives data later but in the same order as the writes."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "Use [Azure Monitor](https://docs.microsoft.com/en-us/azure/cosmos-db/monitor-cosmos-db) to see the provisioned autoscale max RU/s (Autoscale Max Throughput) and the RU/s the system is currently scaled to (Provisioned Throughput)."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "Understand your traffic pattern in order to pick the right option for [provisioned throughput types](https://docs.microsoft.com/en-us/azure/cosmos-db/how-to-choose-offer)."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "For new applications, if you don’t know your traffic pattern yet, start at the entry point RU/s to avoid over-provisioning in the beginning."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "For existing applications:",
    "children": [
      {
        "title": "Use Azure Monitor metrics to determine if your traffic pattern is suitable for autoscale. "
      },
      {
        "title": "Find the normalized request unit consumption metric of your database or container. Normalized utilization is a measure of how much you are currently using your standard (manual) provisioned throughput. "
      },
      {
        "title": "The closer the number is to 100%, the more you are fully using your provisioned RU/s. "
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "Of all hours in a month, if you set provisioned RU/s T and use the full amount for 66% of the hours or more, it's estimated you'll save with standard (manual) provisioned RU/s. If you set autoscale max RU/s Tmax and use the full amount Tmax for 66% of the hours or less, it's estimated you'll save with autoscale."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "If multi-master option is enabled on Cosmos DB, it is important to understand [Conflict Types and Resolution Policies](https://docs.microsoft.com/en-us/azure/cosmos-db/conflict-resolution-policies)."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "[Selecting a partition key](https://docs.microsoft.com/en-us/azure/cosmos-db/partitioning-overview#choose-partitionkey) is a simple, but very important design choice:",
    "children": [
      {
        "title": "You cannot change partition key after it's been created with the collection."
      },
      {
        "title": "Your partition key should be a property that has a value which does not change. If a property is your partition key, you can't update that property's value."
      },
      {
        "title": "Make sure picking a partition key which has a high cardinality. The property should have a wide range of possible values."
      },
      {
        "title": "Your partition key should spread RU consumption and data storage evenly across all logical partitions. This ensures even RU consumption and storage distribution across your physical partitions."
      },
      {
        "title": "Make sure you are running read queries with the partitioned column as it will reduce RU consumption and latency."
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "For query-intensive workloads, use Windows 64-bit instead of Linux or Windows 32-bit host processing."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "If client is consuming more than 50,000 RU/s, there could be bottleneck due to machine capping out on CPU or network utilization. If you reach this point, it is recommended to scale out client applications across multiple servers."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "Call [OpenAsync](https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.documents.client.documentclient.openasync?view=azure-dotnet) to avoid startup latency on first request."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "In order to avoid network latency, collocate client in same region as Cosmos DB."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "Increase the number of threads /tasks."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "To reduce latency and CPU jitter, it is recommended to enable accelerated networking on client virtual machines both [Windows](https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-powershell) and [Linux](https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-cli).    "
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "Implement [retry logic](https://docs.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#cosmos-db) in your client."
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "In order to check if multi location is not selected you can use the following query: ",
    "code": "Resources\n|where  type =~ 'Microsoft.DocumentDb/databaseAccounts'\n|where array_length( properties.locations) <=1\n"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "To check for cosmosdb instances where automatic failover is not enabled:",
    "code": "Resources\n|where  type =~ 'Microsoft.DocumentDb/databaseAccounts'\n|where properties.enableAutomaticFailover!=True\n"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "Query to see the list of multi-region writes:",
    "code": "resources\n| where type == \"microsoft.documentdb/databaseaccounts\"\n and properties.enableMultipleWriteLocations == \"true\"\n"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "To see the consistency levels for your cosmos db accounts you can use the query below: ",
    "code": "Resources\n| project name, type, location, consistencyLevel = properties.consistencyPolicy.defaultConsistencyLevel \n| where type == \"microsoft.documentdb/databaseaccounts\" \n| order by name asc\n"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "[High Availability in Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/high-availability)"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "[Auto-Scale FAQ](https://docs.microsoft.com/en-us/azure/cosmos-db/autoscale-faq)"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Cosmos DB",
    "title": "[Performance Tips for Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/performance-tips)"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure Cache for Redis",
    "title": "99.9% SLA for the cache endpoints and internet gateway will have connectivity"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure Cache for Redis",
    "title": "SLA only covers Standard and Premium tier caches. Basic tier is not covered.",
    "context": "[Azure Cache for Redis Service Level Agreements](https://azure.microsoft.com/en-us/support/legal/sla/cache/v1_0)",
    "children": [
      {
        "title": "Redis (REmote DIctionary Server) is an in memory cache for key value pairs and has High Availablity (HA) by default (except Basic tier). There are three tiers for Azure Cache for Redis: Basic, Standard and Premium."
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure Cache for Redis",
    "title": "Basic - (Not recommended for production workloads) Single node, multiple sizes, ideal for development/test and non-critical workloads. The basic tier has no SLA."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure Cache for Redis",
    "title": "Standard - A replicated cache in a two node Primary/Secondary configuration managed by Microsoft, with a high availability SLA."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure Cache for Redis",
    "title": "Premium - Includes all standard-tier features and including the following:",
    "children": [
      {
        "title": "Faster hardware/performance compared to Basic or Standard-tier"
      },
      {
        "title": "Larger cache size (up to 120GB)"
      },
      {
        "title": "[Data persistence](https://redis.io/topics/persistence): RDB (Redis Database File) and AOF (Append Only File)"
      },
      {
        "title": "VNET support"
      },
      {
        "title": "[Clustering](https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-how-to-premium-clustering)"
      },
      {
        "title": "Geo-Replication - a secondary cache is in another region and replicates data from the primary for disaster recovery. To failover to the secondary, the caches need to be unlinked manually and then the secondary is availabile for writes. The application writing to Redis will need to be updated with the secondary's cache connection string."
      },
      {
        "title": "Availability Zones (preview) - Deploy the cache and replicas across availability zones. Note: By default, each deployment will have one replica per shard. Persistence, clustering, and geo-replication are all disabled at this time with deployments that have more than one replica. Your nodes will be distributed evenly across all zones. You should have a replica count >= number of zones."
      },
      {
        "title": "Import/Export"
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure Cache for Redis",
    "title": "Schedule Updates - Schedule the days and times that Redis Server updates will be applied to the cache. This does not include Azure updates or updates to the VM operating System. "
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure Cache for Redis",
    "title": "Monitor the cache and/or set alerts for exceptions, high CPU, high memory usage, server load and evicted keys for insights when to scale the cache. If the cache needs to be scaled, understanding when to scale is important because it will increase CPU during the scaling event to migrate data."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure Cache for Redis",
    "title": "Deploying the cache inside of a VNET gives the customer more control over the traffic that is able to connect to the cache. Make sure that the subnet has sufficient address space available to deploy the cache nodes and shards (cluster)."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure Cache for Redis",
    "title": "Configure Data Persistence to save a copy of the cache to Azure Storage or use Geo-Replication depending on the business requirement.",
    "children": [
      {
        "title": "Data Persistence - if the master and replica reboot, the data will automatically be loaded from the storage account"
      },
      {
        "title": "Geo-Replication - the secondary cache needs to be unlinked from the primary. The secondary will now become the primary and be able to receive 'writes'."
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure Cache for Redis",
    "title": "Use one static or singleton implementation of the connection multiplexer to Redis and follow the [best practices guide](https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-best-practices)."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure Cache for Redis",
    "title": "Review the [How to administer Azure Cache for Redis](https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-administration#reboot) to understand how data loss can occur with cache reboots and how to test the application for resiliency."
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Data",
    "subCategory": "Azure Cache for Redis",
    "title": "Query to identify Redis Instances that are not on the premium tier:",
    "code": "Resources \n| where type == 'microsoft.cache/redis'\n| where properties.sku.name != 'Premium'\n"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Hybrid",
    "subCategory": "Azure Stack Hub",
    "title": "Microsoft does not provide an SLA for Azure Stack Hub because Microsoft does not have control over customer datacenter reliability, people, and processes."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Hybrid",
    "subCategory": "Azure Stack Hub",
    "title": "Azure Stack Hub currently only supports a single Scale Unit (SU) within in a single Region, which can consist of between 4 and 16 servers that use Hyper-V failover clustering; each region serves as an independent Azure Stack Hub \"stamp\" with separate portal and API endpoints.",
    "context": "Azure Stack Hub does therefore **not support Availability Zones** as it currently consists only of a single \"region\" (aka a single physical location). High availability to cope with outages of a single location should be implemented by using two Azure Stack Hub instances deployed into different physical locations."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Hybrid",
    "subCategory": "Azure Stack Hub",
    "title": "Azure Stack Hub supports **Premium Storage** to ensure compatibility, however, provisioning premium storage accounts or disks does not guarantee that storage objects will be allocated onto SSD or NVMe drives."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Hybrid",
    "subCategory": "Azure Stack Hub",
    "title": "Azure Stack Hub supports only a subset of [VPN Gateway SKUs](https://docs.microsoft.com/en-us/azure-stack/user/azure-stack-vpn-gateway-about-vpn-gateways#estimated-aggregate-throughput-by-sku) available in Azure with a limited bandwidth of 100 or 200 Mbps. ",
    "context": "Only one site-to-site (S2S) VPN connection can be created between two Azure Stack Hub deployments. This is due to a limitation in the platform that only allows a single VPN connection to the same IP address. Multiple S2S VPN connections with higher throughput can be established using 3rd-party NVAs."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Hybrid",
    "subCategory": "Azure Stack Hub",
    "title": "Azure Stack Hub does currently not support [Virtual network peering](https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-peering-overview). ",
    "context": "Two networks (on the same Azure Stack Hub \"stamp\") can also not be connected via Azure (Stack) VPN GWs as they're sharing the same IP address. Virtual networks on Azure Stack Hub can be connected using 3rd-party NVAs (e.g. [Fortinet Fortigate](https://docs.microsoft.com/en-us/azure-stack/user/azure-stack-network-howto-vnet-to-vnet?view=azs-2002))."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Hybrid",
    "subCategory": "Azure Stack Hub",
    "title": "Treat Azure Stack Hub as a scale unit and deploy multiple instances to remove Azure Stack Hub as a single point of failure for encompassed workloads. ",
    "children": [
      {
        "title": "Deploy workloads in either an active-active or active-passive configuration across Azure Stack Hub stamps and/or Azure."
      }
    ]
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Hybrid",
    "subCategory": "Azure Stack Hub",
    "title": "Apply general Azure configuration recommendations for all Azure Stack Hub services."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Grid",
    "title": "Azure EventGrid provides a 99.99% uptime SLA"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Grid",
    "title": "In case of a multi-region Azure solution, deploy an Event Grid instance per region."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Grid",
    "title": "In high-throughput scenarios, use batched events. This means that the service will deliver a json array with multiple events to the subscribers, instead of an array with one event. The consuming application must be able to process these arrays."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Grid",
    "title": "Event batches cannot exceed 1MB in size. This means that if the message payload is large, only one or a few messages will fit in the batch. This means that the consuming service will need to process more event batches. If your event has a large payload, consider storing it elsewhere (e.g. blob storage) and passing a reference in the event. When integrating with third-party services through the CloudEvents schema, it is recommended [not to exceed 64kb events](https://github.com/cloudevents/spec/blob/v1.0/spec.md#size-limits)."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Grid",
    "title": "Batch size selection depends on the payload size and the message volume. This should be a configurable parameter and optimizing this should be done during load-testing. "
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Grid",
    "title": "If EventGrid delivers to an endpoint that holds custom code, ensure that the message is accepted with an HTTP 200-204 response only when it can be successfully processed. "
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Grid",
    "title": "Monitor EventGrid for failed event publishing (Publish Failed metric). Additionally, the 'Unmatched' metric will show messages that are published, but not matched to any subscription. Depending on your application architecture, the latter may be intentional."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Grid",
    "title": "Monitor EventGrid for failed event delivery. The 'Delivery Failed' metric will increase every time a message cannot be delivered to an event handler (timeout or a non 200-204 HTTP status code). Additionally, if an event must not be lost, set up a Dead-Letter-Queue (DLQ) storage account. This is where events that cannot be delivered after the maximum retry count will be placed. Optionally, implement a notification system on the DLQ storage account, e.g. by handling a 'new file' event through Event Grid."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "Azure Event Hubs has a [published SLA](https://azure.microsoft.com/en-us/support/legal/sla/event-hubs) of 99.95% for the Basic and Standard Tiers, and 99.99% for the Dedicated Tier."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "The number of partitions reflect the degree of downstream parallelism you can achieve. For maximum throughput, use the maximum number of partitions (32) when creating the Event Hub. This will allow you to scale up to 32 concurrent processing entities and will offer the highest send/receive availability."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "In high-throughput scenarios, use batched events. This means that the service will deliver a json array with multiple events to the subscribers, instead of an array with one event. The consuming application must be able to process these arrays."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "As part of your solution-wide availability and disaster recovery strategy, consider enabling the EventHub geo disaster-recovery option. This will allow the creation of a secondary namespace in a different region. Note that only the active namespace receives messages at any time and that messages and events themselves are not replicated to the secondary region. ",
    "context": "Note: The RTO for the regional failover is 'up to 30 minutes'. Confirm this aligns with the requirements of the customer and fits in the broader availability strategy. If a higher RTO is required, consider implementing a client-side failover pattern too."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "When developing new applications, use EventProcessorClient (.Net and Java) or EventHubConsumerClient (Python and Javascript) as the client SDK. EventProcessorHost has been deprecated."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "Every consumer can read events from 1 to 32 partitions. To achieve maximum scale on the side of the consuming application, every consumer should read from a single partition. "
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "Do not publish events to a specific partition. If ordering of events is essential, implement this downstream or use a different messaging service instead."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "Create SendOnly and ListenOnly policies for the event publisher and consumer, respectively."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "When publishing events frequently, use the AMQP protocol when possible. AMQP has higher network costs when initializing the session, however HTTPS requires additional TLS overhead for every request. AMQP has higher performance for frequent publishers."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "When a solution has a large number of independent event publishers, consider using Event Publishers for fine-grained access control. Note that is automatically sets the partition key to the publisher name, so this should only be used if the events originate from all publishers evenly. "
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "When using the Capture feature, carefully consider the configuration of the time window and file size, especially with low event volumes. Data Lake will charge small for a minimal file size for storage (gen1) or minimal transaction size (gen2). This means that if you set the time window so low that the file has not reached minimum size, you will incur a lot of extra cost."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "Ensure each consuming application uses a separate consumer group and only one active receiver per consumer group is in place. "
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "When using the SDK to send events to Event Hubs, ensure the exceptions thrown by the [retry policy](https://docs.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#event-hubs) (EventHubsException or OperationCancelledException) are properly caught. When using HTTPS, ensure a proper retry pattern is implemented."
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Event Hub",
    "title": "Find Event Hub namespaces with 'Basic' SKU:",
    "code": "Resources \n| where type == 'microsoft.eventhub/namespaces'\n| where sku.name == 'Basic'\n| project resourceGroup, name, sku.name\n"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "For Service Bus Queues and Topics, Microsoft guarantees that at least 99.9% of the time, properly configured applications will be able to send or receive messages or perform other operations on a deployed Queue or Topic. [SLA Documentation](https://azure.microsoft.com/en-us/support/legal/sla/service-bus)"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "However, when deploying Service Bus with Geo-disaster recovery and in availability zones, the SLO increases dramatically, but does not change the financially backed SLA of 99.9% availability."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "[Partitioned Queues and Topics](https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-partitioning)"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "[Express Entities](https://docs.microsoft.com/en-us/dotnet/api/microsoft.servicebus.messaging.queuedescription.enableexpress)"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "In addition to the documentation on [Service Bus Premium and Standard messaging tiers](https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-premium-messaging), these features are only available on the Premium SKU.",
    "children": [
      {
        "title": "Dedicated resources"
      },
      {
        "title": "Virtual network integration: Limits the networks that can connect to the Service Bus instance. Requires Service Endpoints to be enabled on the subnet. There are Trusted Microsoft services that are not supported when Virtual Networks are implemented (i.e., integration with Event Grid) https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-service-endpoints"
      },
      {
        "title": "Private endpoints"
      },
      {
        "title": "IP Filtering/Firewall: Restrict connections to only defined IPv4 addresses or IPv4 address ranges"
      },
      {
        "title": "[Availability zones](https://docs.microsoft.com/en-us/azure/availability-zones/az-overview): Provides enhanced availability by spreading replicas across availability zones within one region at no additional cost"
      },
      {
        "title": "Event Grid Integration: [Available event types](https://docs.microsoft.com/en-us/azure/event-grid/event-schema-service-bus)"
      },
      {
        "title": "Scale Messaging Units"
      },
      {
        "title": "[Geo-Disaster Recovery](https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-geo-dr) (paired namespace)"
      },
      {
        "title": "BYOK (Bring Your Own Key): Azure Service Bus encrypts data at rest and automatically decrypts it when accessed, but customers can also bring their own customer-managed key."
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "If you need mission critical messaging with queues/topics, Service Bus Premium is recommended with Geo-Disaster Recovery. Choosing the pattern is dependent on the business requirements and the recovery time objective (RTO)."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "Geo-Disaster",
    "children": [
      {
        "title": "[Active/Active](https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-outages-disasters#active-replication)"
      },
      {
        "title": "[Active/Passive](https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-outages-disasters#passive-replication)"
      },
      {
        "title": "[Paired Namespace (Active/Passive)](https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-geo-dr)"
      },
      {
        "title": "NOTE: the secondary region should be an Azure paired region. https://docs.microsoft.com/en-us/azure/best-practices-availability-paired-regions "
      }
    ]
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "Make the namespace zone redundant (only available with Premium)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "Review the Service Bus performance improvements documentation https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-performance-improvements"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "Connect to Service Bus with the AMQP protocol and utilize Service Endpoints or Private Endpoints when possible. This keeps traffic on the Azure Backbone. Note: the default connection protocol for Microsoft.Azure.ServiceBus and Windows.Azure.ServiceBus namespaces is AMQP."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "Ensure that Service Bus messaging exceptions are handled properly.",
    "context": "[Service Bus Messaging Exceptions](https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-exceptions)"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "Query to identify Service Bus Instances that are not on the premium tier:",
    "code": "Resources\n| where\n\ttype == 'microsoft.servicebus/namespaces'\n| where\n\tsku.tier != 'Premium'\n"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "Query to identify premium Service Bus Instances that are not zone redundant:",
    "code": "Resources\n| where\n\ttype == 'microsoft.servicebus/namespaces'\n| where\n\tsku.tier == 'Premium'\n\tand properties.zoneRedundant == 'false'\n"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Service Bus",
    "title": "Query to identify premium Service Bus Instances that are not using private endpoints:",
    "code": "Resources\n| where\n\ttype == 'microsoft.servicebus/namespaces'\n| where\n\tsku.tier == 'Premium'\n\tand isempty(properties.privateEndpointConnections)\n"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Storage Queues",
    "title": "Azure Storage Queues follow the SLA statements of the general [Storage Account service](https://azure.microsoft.com/en-us/support/legal/sla/storage/v1_5/). Currently (v1.5) this specifies a 99.9% guarantee for LRS, ZRS and GRS accounts and a 99.99% guarantee for RA-GRS (provided that requests to RA-GRS switch to secondary endpoints if there is no success on the primary endpoint)"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Storage Queues",
    "title": "Since Storage Queues are part of the Azure Storage service, please refer to the general storage guidance, in addition to the configuration recommendations mentioned below."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Storage Queues",
    "title": "Using geo-zone-redundant storage (GZRS) or read-access geo-zone-redundant storage (RA-GZRS) will provide 16 nines or durability and will protect against failover if an entire datacenter becomes unavailable. https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy "
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Storage Queues",
    "title": "For an SLA increase from three to four nines, use geo-redundant storage with read access and configure the client application to fail over to secondary read endpoints if the primary endpoints fail to respond. This consideration should be part of the overall reliability strategy of your solution."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Storage Queues",
    "title": "Refer to the 'Storage' guidance for specifics on data recovery for storage accounts"
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Storage Queues",
    "title": "Ensure that for all clients accessing the storage account, a proper [retry policy](https://docs.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#azure-storage) is implemented."
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Storage Queues",
    "title": "Query to identify storage accounts using V1 storage accounts:",
    "code": "Resources\n| where\n\ttype == 'microsoft.storage/storageaccounts'\n\tand kind == 'Storage'\n"
  },
  {
    "type": "Supporting Source Artifacts",
    "pillars": [
      "reliability"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "Storage Queues",
    "title": "Query to identify storage accounts using locally redundant storage (LRS):",
    "code": "Resources\n| where\n\ttype == 'microsoft.storage/storageaccounts'\n\tand sku.name =~ 'Standard_LRS'\n"
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub",
    "title": "Azure IoT Hub has a [published SLA](https://azure.microsoft.com/en-us/support/legal/sla/iot-hub) of 99.9% for the Basic and Standard tiers, there is no SLA for the Free tier."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub",
    "title": "The number of Device-to-cloud partitions for the Event Hub-compatible endpoint reflect the degree of downstream parallelism you can achieve. For maximum throughput, use the maximum number of partitions (32) when creating the IoT Hub - if you are planning to use the built-in endpoint. This will allow you to scale up to 32 concurrent processing entities and will offer the highest send/receive availability. This number cannot be changed after creation."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub",
    "title": "In high-throughput scenarios, use batched events. This means that the service will deliver an array with multiple events to the consumers, instead of an array with one event. The consuming application must be able to process these arrays."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub",
    "title": "As part of your solution-wide availability and disaster recovery strategy, consider using the IoT Hub [cross-region Disaster Recovery option](https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-ha-dr#cross-region-dr). This will move the IoT Hub endpoint to the paired Azure region. Note that only the device registry gets replicated. Events themselves are not replicated to the secondary region.",
    "context": "Note: The RTO for the customer-initiated failover is 'between 10 minutes to a couple of hours'. For a Microsoft-initiated failover the RTO is '2-26 hours'. Confirm this aligns with the requirements of the customer and fits in the broader availability strategy. If a higher RTO is required, consider implementing a client-side failover pattern, too."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub",
    "title": "When sending events frequently, use the AMQP or MQTT protocol when possible. AMQP and MQTT have higher network costs when initializing the session, however HTTPS requires additional TLS overhead for every request. AMQP and MQTT have higher performance for frequent publishers."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub",
    "title": "When using an SDK to send events to IoT Hubs, ensure the exceptions thrown by the [retry policy](https://docs.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific#iot-hub) (EventHubsException or OperationCancelledException) are properly caught. When using HTTPS, ensure a proper retry pattern is implemented."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub",
    "title": "When using message routing feature in IoT Hub, latency of the message delivery increases. On average this [should not exceed 500 ms](https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-devguide-messages-d2c#latency), but be aware that there is no guarantee for the delivery latency. If you require the minimum possible latency, consider to not use routing and read the events from the built-in endpoint."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub",
    "title": "If you are using [X.509 certificates](https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-security-x509-get-started#get-x509-ca-certificates) for the device connection, it is recommended to use only certificates validated by a root CA in production environment. Make sure you have processes in place to update the certificate before they expire."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub",
    "title": "Adding more than one IoT Hub per region does not offer additional resiliency as chances are, that all hubs might still run on the same underlying cluster. For scaling reasons it is usually sufficient to increase the tier and/or allocated IoT Hub units."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub",
    "title": "If the RTOs offered by either customer- or Microsoft-initiated failover (see above) are not sufficient, it is recommended to provision a second IoT Hub in another region and have routing logic on the device. This can be further enhanced with a 'Concierge Service'. See [here](https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-ha-dr#achieve-cross-region-ha) for more details."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub",
    "title": "To avoid telemetry interruption due to throttling / fully used quota, consider adding a [custom auto-scaling solution](https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-scaling#auto-scale)."
  },
  {
    "type": "Configuration Recommendations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub",
    "title": "When reading device telemetry from the built-in Event Hub-compatible endpoint, refer to the recommendation regarding [Event Hub consumers](#Event-Hub) in this document."
  },
  {
    "type": "Design Considerations",
    "pillars": [
      "reliability",
      "operationalexcellence"
    ],
    "lens": "service",
    "category": "Messaging",
    "subCategory": "IoT Hub Device Provisioning Service",
    "title": "Azure IoT Hub Device Provisioning Service has a [published SLA](https://azure.microsoft.com/en-us/support/legal/sla/iot-hub) of 99.9%."
  }
]
