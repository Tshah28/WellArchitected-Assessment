[
    {
        "type": "Design Considerations",
        "pillars": [
            "reliability",
            "operationalexcellence",
            "security"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Storage account names must be between 3 and 24 characters in length and may contain numbers and lowercase letters only."
    },
    {
        "type": "Design Considerations",
        "pillars": [
            "reliability",
            "operationalexcellence",
            "security"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Storage account names must be unique within Azure. No two storage accounts can have the same name."
    },
    {
        "type": "Design Considerations",
        "pillars": [
            "reliability",
            "operationalexcellence",
            "security"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "The current [SLA for Storage Accounts](https://azure.microsoft.com/support/legal/sla/storage/v1_5/) (v1.5, June 2019) specifies a 99.9% guarantee for LRS, ZRS and GRS accounts and a 99.99% guarantee for RA-GRS (provided that requests to RA-GRS switch to secondary endpoints if there is no success on the primary endpoint) to successfully process requests to **read data**. And at least 99.9% to successfully process requests to **write data**. SLAs for other storage tiers might differ. Go to [Azure Storage redundancy](https://docs.microsoft.com/azure/storage/common/storage-redundancy) to see which redundancy option is best for a specific scenario."
    },
    {
        "type": "Configuration Recommendations",
        "pillars": [
            "operationalexcellence",
            "security"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Enable Azure Defender for all of your storage accounts",
        "context" : "Azure Defender for Azure Storage provides an additional layer of security intelligence that detects unusual and potentially harmful attempts to access or exploit storage accounts. Security alerts are triggered in Azure Security Center when anomalies in activity occur and are also sent via email to subscription administrators, with details of suspicious activity and recommendations on how to investigate and remediate threats. For more information, see [Configure Azure Defender for Azure Storage](https://docs.microsoft.com/azure/storage/common/azure-defender-storage-configure)."
    },
    {
        "type": "Design Considerations",
        "pillars": [
            "reliability",
            "operationalexcellence"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "General-purpose v1 storage accounts provide access to all Azure Storage services, but may not have the latest features or the lowest per gigabyte pricing. It is recommended to use general-purpose v2 storage accounts in most cases. Reasons to still use v1 are:\n   * Applications require the classic deployment model.\n   * Applications are transaction-intensive or use significant geo-replication bandwidth, but don't require large capacity.\n   * The use of a Storage Service REST API that is earlier than 2014-02-14 or a client library with a version lower than 4.x is required and an application upgrade is not possible.\n\n    See [Storage account overview](https://docs.microsoft.com/azure/storage/common/storage-account-overview) for more."
    },
    {
        "type": "Configuration Recommendations",
        "pillars": [
            "reliability",
            "operationalexcellence",
            "security"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Turn on soft delete for blob data",
        "context" : "[Soft delete for Azure Storage blobs](https://docs.microsoft.com/azure/storage/blobs/storage-blob-soft-delete) enables you to recover blob data after it has been deleted."
    },
    {
        "type": "Configuration Recommendations",
        "pillars": [
            "reliability",
            "operationalexcellence",
            "security"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Use Azure AD to authorize access to blob data",
        "context" : "Azure AD provides superior security and ease of use over Shared Key for authorizing requests to Blob storage. It is recommended to use Azure AD authorization with your blob and queue applications when possible to minimize potential security vulnerabilities inherent in Shared Key. For more information, see [Authorize access to Azure blobs and queues using Azure Active Directory](https://docs.microsoft.com/azure/storage/common/storage-auth-aad).",
        "children": [
            {
                "title": "Keep in mind the principal of least privilege when assigning permissions to an Azure AD security principal via Azure RBAC",
                "context": "When assigning a role to a user, group, or application, grant that security principal only those permissions that are necessary for them to perform their tasks. Limiting access to resources helps prevent both unintentional and malicious misuse of your data."
            },
            {
                "title": "Use Managed Identities to access blob and queue data",
                "context" : "Azure Blob and Queue storage support Azure AD authentication with [managed identities for Azure resources](https://docs.microsoft.com/azure/active-directory/managed-identities-azure-resources/overview). Managed identities for Azure resources can authorize access to blob and queue data using Azure AD credentials from applications running in Azure virtual machines (VMs), function apps, virtual machine scale sets, and other services. By using managed identities for Azure resources together with Azure AD authentication, you can avoid storing credentials with your applications that run in the cloud as well as issues with expiring service principals. See [Authorize access to blob and queue data with managed identities for Azure resources](https://docs.microsoft.com/azure/storage/common/storage-auth-aad-msi) for more information."
            }
        ]
    },
    {
        "type": "Configuration Recommendations",
        "pillars": [
            "reliability",
            "operationalexcellence",
            "security"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Use blob versioning or immutable blobs to store business-critical data",
        "context" : "Consider using [Blob versioning](https://docs.microsoft.com/azure/storage/blobs/versioning-overview) to automatically maintain previous versions of an object or the use of legal holds and time-based retention policies to store blob data in a WORM (Write Once, Read Many) state. Blobs stored immutably can be read, but cannot be modified or deleted for the duration of the retention interval. For more information, see [Store business-critical blob data with immutable storage](https://docs.microsoft.com/azure/storage/blobs/storage-blob-immutable-storage)."
    },
    {
        "type": "Configuration Recommendations",
        "pillars": [
            "reliability",
            "operationalexcellence",
            "security"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Enable the Secure transfer required option on all of your storage accounts",
        "context": "When you enable the Secure transfer required option, all requests made against the storage account must take place over secure connections. Any requests made over HTTP will fail. For more information, see [Require secure transfer in Azure Storage](https://docs.microsoft.com/azure/storage/common/storage-require-secure-transfer).",
        "children": [
            {
                "title": "Limit shared access signature (SAS) tokens to HTTPS connections only",
                "context" : "Requiring HTTPS when a client uses a SAS token to access blob data helps to minimize the risk of eavesdropping. For more information, see [Grant limited access to Azure Storage resources using shared access signatures (SAS)](https://docs.microsoft.com/azure/storage/common/storage-sas-overview)."                
            },
            {
                "title": "Avoid/prevent using Shared Key authorization to access Storage Accounts",
                "context": "It is recommended to use Azure AD to authorize requests to Azure Storage and possible to [prevent Shared Key Authorization](https://docs.microsoft.com/azure/storage/common/shared-key-authorization-prevent). For scenarios that require Shared Key authorization, always prefer SAS tokens over distributing the Shared Key."
            },
            {
                "title": "Regenerate your account keys periodically",
                "context": "Rotating the account keys periodically reduces the risk of exposing your data to malicious actors."
            },
            {
                "title": "Have a revocation plan in place for any SAS that you issue to clients",
                "context": "If a SAS is compromised, you will want to revoke that SAS as soon as possible. To revoke a user delegation SAS, revoke the user delegation key to quickly invalidate all signatures associated with that key. To revoke a service SAS that is associated with a stored access policy, you can delete the stored access policy, rename the policy, or change its expiry time to a time that is in the past."
            },
            {
                "title": "Use near-term expiration times on an ad hoc SAS, service SAS or account SAS",
                "context": "If a SAS is compromised, it's valid only for a short time. This practice is especially important if you cannot reference a stored access policy. Near-term expiration times also limit the amount of data that can be written to a blob by limiting the time available to upload to it. Clients should renew the SAS well before the expiration, in order to allow time for retries if the service providing the SAS is unavailable."
            }
        ]
    },
    {
        "type": "Configuration Recommendations",
        "pillars": [
            "reliability",
            "operationalexcellence",
            "security"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Restrict default Internet access for Storage Accounts",
        "context" : "By default network access to Storage Accounts is not restricted and open to all traffic coming from the Internet. Access to storage accounts should be granted to specific [Azure Virtual Networks only](https://docs.microsoft.com/azure/storage/common/storage-network-security) whenever possible or use [private endpoints](https://docs.microsoft.com/azure/private-link/private-endpoint-overview) to allow clients on a virtual network (VNet) to securely access data over a [Private Link](https://docs.microsoft.com/azure/private-link/private-link-overview). See [Use private endpoints for Azure Storage](https://docs.microsoft.com/azure/storage/common/storage-private-endpoints) for more. Exception can be made for Storage Accounts that need to be accessible via the Internet.",
        "children": [
            {
                "title": "Enable firewall rules",
                "context": "Configure firewall rules to limit access to your storage account to requests that originate from specified IP addresses or ranges, or from a list of subnets in an Azure Virtual Network (VNet). For more information about configuring firewall rules, see [Configure Azure Storage firewalls and virtual networks](https://docs.microsoft.com/azure/storage/common/storage-network-security)."
            },
            {
                "title": "Limit network access to specific networks",
                "context": "[Limiting network access](https://docs.microsoft.com/azure/storage/common/storage-network-security) to networks hosting clients requiring access reduces the exposure of your resources to network attacks either by using the built-in [Firewall and virtual networks](https://docs.microsoft.com/azure/storage/common/storage-network-security) functionality or by using [private endpoints](https://docs.microsoft.com/azure/storage/common/storage-private-endpoints)."
            },
            {
                "title": "Allow trusted Microsoft services to access the storage account",
                "context": "Turning on firewall rules for storage accounts blocks incoming requests for data by default, unless the requests originate from a service operating within an Azure Virtual Network (VNet) or from allowed public IP addresses. Requests that are blocked include those from other Azure services, from the Azure portal, from logging and metrics services, and so on. You can permit requests from other Azure services by adding an exception to allow trusted Microsoft services to access the storage account. For more information about adding an exception for trusted Microsoft services, see [Configure Azure Storage firewalls and virtual networks](https://docs.microsoft.com/azure/storage/common/storage-network-security)."
            }
        ]
    },
    {
        "type": "Configuration Recommendations",
        "pillars": [
            "costoptimization"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Are you saving by reserving capacity for data for block blob storage?",
        "context" : "Money can be saved by reserving capacity for block blob and for Azure Data Lake Storage gen 2 data in standard storage account when customer commits to 1 or 3 years reservation."
    },
    {
        "type": "Configuration Recommendations",
        "pillars": [
            "costoptimization"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Disks",
        "title": "Are you using Premium disks (P30 & above)? ",
        "context" : "Premium Disks (P30 & above) can be reserved (1 or 3 years) at discounted price."
    },
    {
        "type": "Configuration Recommendations",
        "pillars": [
            "costoptimization"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Are you organizing data into access tiers?",
        "context" : "You can reduce cost by placing blob data into the most cost-effective access tier. Place frequently accessed data in hot tier, less frequent in cold or archive tier. Use Premium storage for workloads with high transaction volumes or ones where latency is critical."
    },
    {
        "type": "Configuration Recommendations",
        "pillars": [
            "costoptimization"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Are you using lifecycle policy to move data between access tiers?",
        "context" : "Lifecycle management policy periodically moves data between tiers. Policies can move data based on rules that specified by the user. For example, you might create rules that move blobs to the archive tier if that blob has not been modified in 90 days. Unused data can be also completely removed using a policy. By creating policies that adjust the access tier of your data, you can design the least expensive storage options for your need. "
    },
    {
        "type": "Configuration Recommendations",
        "pillars": [
            "costoptimization"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Disks",
        "title": "Are you utilizing bursting for P20 and below disks for workload such as batch jobs, workload which handle traffic spikes, and for improving OS boot time?",
        "context" : "Azure Disks offer variety of SKUs and sizes to satisfy different workload requirements. Some of the more recent features could help further optimize cost-performance of existing disk use cases. Firstly, you can leverage disk bursting for Premium (disks P20 and below). Example scenarios that could benefit from this feature are improving OS boot time, handling batch jobs and handling traffic spikes. "
    },
    {
        "type": "Design Considerations",
        "pillars": [
            "costoptimization"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Disks",
        "title": "Are you leveraging shared disk for workload such SQL server failover cluster instance (FCI), file server for general use (IW workload) and SAP ASCS/SCS?",
        "context" : "You can leverage shared disks (in preview as of 11/2020) to enable cost-effective clustering instead of setting up own shared disks via S2D (Storage Spaces Direct). Sample workloads that would benefit from shared disks are: SQL Server Failover Cluster Instances (FCI), Scale-out File Server (SoFS), File Server for General Use (IW workload) and SAP ASCS/SCS."
    },
    {
        "type": "Configuration Recommendations",
        "pillars": [
            "costoptimization"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Disks",
        "title": "For database workloads, are you configuring data and log files on different disks?",
        "context" : "You can optimize IaaS DB workload performance by configuring system, data and log files to be on different disk SKUs (leveraging Premium Disks for data and Ultra Disks for logs satisfies most production scenarios). Further, Ultra Disk cost/performance can be optimized by taking advantage of the ability to configure capacity, IOPS and throughput independently; and ability to dynamically configure these attributes. Example workloads are SQL on IaaS, Cassandra DB, Maria DB, MySql and Mongo DB on IaaS."
    },
    {
        "type": "Design Consideration",
        "pillars": [
            "costoptimization"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Are you periodically disposing or cleaning up unused storage resources (e.g. unattached disks, old snapshots)?",
        "context" : "Unused storage resources can incur cost and its good idea to regularly perform cleanup to reduce cost."
    },
    {
        "type": "Design Consideration",
        "pillars": [
            "costoptimization"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Disks",
        "title": "Are you using selective disk backup and restore for Azure VMs?",
        "context" : "Using the selective disks backup and restore functionality, you can back up a subset of the data disks in a VM. This provides an efficient and cost-effective solution for your backup and restore needs."
    },
    {
        "type": "Design Considerations",
        "pillars": [
            "costoptimization"
        ],
        "lens": "service",
        "category": "Storage",
        "subCategory": "Storage Accounts",
        "title": "Azure Blob access time tracking and access time-based lifecycle management",
        "context" : "(in preview as of 11/2020) Minimize your storage cost automatically by setting up a policy based on last access time to: cost-effective backup storage options. Transition your data from a hotter access tier to a cooler access tier (hot to cool, cool to archive, or hot to archive) if there is no access for a period. Delete your data if there is no access for an extended period."
    }
]